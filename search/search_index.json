{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"pictures/","title":"Pictures","text":"Previous Next"},{"location":"projects/","title":"Projects","text":""},{"location":"projects/#software-development-engineer-envista-october-2024-present","title":"Software Development Engineer - Envista (October 2024 - Present)","text":"<ul> <li>Apply security and compliance best practices in the Spark solution. </li> </ul>"},{"location":"projects/#senior-backend-engineer-maps-api-mapbox-feb-2022-may-2024","title":"Senior Backend Engineer, Maps API - Mapbox (Feb 2022 - May 2024)","text":"<ul> <li>Developed the Static Images API, capable of handling over 6,000 requests per second, with a server-side rendering engine for clients such as Strava and Yahoo Japan Weather.</li> <li>Optimized and repartitioned data on AWS S3 to reduce maintenance costs.</li> <li>Designed ECS capacity management to provision on-demand tasks in response to \u201cSpot interruption\u201d and task placement failures.</li> <li>Developed the Semantic Tiles API as the location provider service for Square Enix, utilized in the Dragon Quest Walk game.</li> <li>Enhanced the scalability of the Geocoding API by sharding the search index based on request categories.</li> <li>Increased the availability of the Tiling Service by designing replication and failover strategies to ensure continuity during regional S3 outages.</li> <li>Revived Atlas with major security updates.</li> <li>Participated in the on-call rotation to ensure the high availability, performance, and resilience of our services.</li> </ul>"},{"location":"projects/#senior-software-engineer-f-secure-nov-2019-jan-2022","title":"Senior Software Engineer - F-Secure (Nov 2019 - Jan 2022)","text":"<ul> <li>Developed the backend for SENSE-enabled routers, including:<ul> <li>Pairing service for SENSE mobile app registration</li> <li>Managing data for routers and connected devices</li> <li>Configuration management for operators</li> <li>Management of user profiles and features</li> </ul> </li> </ul>"},{"location":"projects/#senior-developer-bankify-sep-2018-oct-2019","title":"Senior Developer - Bankify (Sep 2018 - Oct 2019)","text":"<ul> <li>Developed the Invoice Barcode Scanner, the primary revenue-generating service of the company.</li> <li>Researched ways to integrate data mining techniques into the automated savings API.</li> <li>Designed a recommendation engine leveraging extracted data from receipt images.</li> <li>Contributed to frontend React components.</li> </ul>"},{"location":"projects/#lead-developer-parsian-insurance-may-2015-aug-2018","title":"Lead Developer - Parsian Insurance (May 2015 - Aug 2018)","text":"<ul> <li>Developed the backend service for Life Insurance system.</li> <li>Designed an end-to-end architecture for the Personal Accident Insurance system.</li> </ul>"},{"location":"projects/#java-ee-developer-rayan-bahman-pardaz-mar-2013-may-2015","title":"Java EE Developer - Rayan Bahman Pardaz (Mar 2013 - May 2015)","text":"<ul> <li>Refactored a legacy HR system to Java EE 6, utilizing EJB on JBoss.</li> </ul>"},{"location":"projects/#software-engineer-persian-search-engine-feb-2011-mar-2013","title":"Software Engineer - Persian Search Engine (Feb 2011 - Mar 2013)","text":"<ul> <li>Modeled documents in vector space.</li> <li>Designed the inverted index.</li> <li>Scheduled MapReduce jobs to update index weights.</li> <li>Implemented ranking algorithms for user queries.</li> </ul>"},{"location":"projects/#software-engineer-mehad-apr-2009-apr-2011","title":"Software Engineer - Mehad (Apr 2009 - Apr 2011)","text":"<ul> <li>Developed a software interface for ECU-PC connections.</li> <li>Integrated a module for connecting to a wireless station for real-time testing.</li> <li>Refactored production software for customized distribution packages.</li> </ul>"},{"location":"projects/#junior-software-engineer-douran-group-sep-2007-oct-2008","title":"Junior Software Engineer - Douran Group (Sep 2007 - Oct 2008)","text":"<ul> <li>Developed the ERP human resources module.</li> <li>Created automated database migration tools for upgrading base information and schemas.</li> <li>Developed a web interface for migration tools to streamline processes.</li> </ul>"},{"location":"projects/#software-analyst-atinegar-mehr-jun-2007-oct-2007","title":"Software Analyst - Atinegar Mehr (Jun 2007 - Oct 2007)","text":"<ul> <li>Reviewed existing software documents for compliance with RUP standards and made necessary revisions.</li> </ul>"},{"location":"projects/#publications","title":"Publications","text":"<ul> <li>A Novel Similarity Measure for Sequence Data</li> <li>NDVI Optimization Using Genetic Algorithm</li> </ul>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/","title":"PostgreSQL Transactions - Part 1","text":"<p>Understanding transactions is a foundational skill in database systems. Transactions are critical for ensuring database reliability and consistency. By exploring transactions, you can:</p> <ul> <li>Build robust, error-resilient applications.</li> <li>Debug database behaviors with confidence.</li> <li>Design systems that handle concurrency and consistency gracefully.</li> </ul> <p>Curiosity about transactions is a gateway to mastering how databases work behind the scenes. PostgreSQL\u2019s handling of transactions, even for simple queries, offers insights into how databases maintain ACID properties (Atomicity, Consistency, Isolation, Durability).</p> <ul> <li>Source code : Spring boot / JPA / PostgreSQL</li> </ul>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#exploring-postgresql-transactions-with-a-simple-select-query-in-spring-boot","title":"Exploring PostgreSQL Transactions with a Simple SELECT Query in Spring Boot","text":"<p>When we think about database transactions, the focus is often on <code>INSERT</code>, <code>UPDATE</code>, or <code>DELETE</code> queries. But did you know that even a simple <code>SELECT</code> query in PostgreSQL is part of a transaction? Let's build a simple demo project to verify this behavior.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#code-setup-a-minimal-spring-boot-example","title":"Code Setup: A Minimal Spring Boot Example","text":"<p>Here\u2019s a simple setup to illustrate the concept:</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#entity","title":"Entity","text":"<pre><code>@Entity\n@Data\npublic class AccountEntity {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    private String name;\n    private int balance;\n}\n</code></pre>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#repository","title":"Repository","text":"<pre><code>public interface AccountRepository extends JpaRepository&lt;AccountEntity, Long&gt; {\n}\n</code></pre>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#service","title":"Service","text":"<pre><code>@Service\n@AllArgsConstructor\npublic class AccountService {\n\n    private final AccountRepository accountRepository;\n\n    public List&lt;AccountEntity&gt; getAllAccounts() {\n        return accountRepository.findAll();\n    }\n}\n</code></pre>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#controller","title":"Controller","text":"<pre><code>@RestController\n@AllArgsConstructor\npublic class AccountController {\n\n    private final AccountService accountService;\n\n    @GetMapping(\"/accounts\")\n    public List&lt;AccountEntity&gt; getAllAccounts() {\n        return accountService.getAllAccounts();\n    }\n}\n</code></pre> <p>To observe transactions in action, enable logging in <code>postgresql.conf</code>:</p> <pre><code>log_statement = 'all'\n</code></pre> <p>Now, make a request to: <pre><code>GET localhost:8080/accounts\n</code></pre></p> <p>Here\u2019s what you\u2019ll see in the PostgreSQL logs:</p> <p><pre><code>execute &lt;unnamed&gt;: BEGIN READ ONLY\nexecute &lt;unnamed&gt;: select ae1_0.id,ae1_0.balance,ae1_0.name from account_entity ae1_0\nexecute &lt;unnamed&gt;: COMMIT\n</code></pre> Notice that the query is executed between BEGIN READ ONLY and COMMIT, which marks the boundaries of the transaction.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#postgresql-transactional-nature","title":"PostgreSQL Transactional Nature","text":"<p>In PostgreSQL, every query is executed in a transaction, whether explicitly declared or not. We didn\u2019t explicitly define <code>@Transactional</code> in our service method <code>getAllAccounts</code>. However, PostgreSQL\u2019s default autocommit mode implicitly wraps the query in its own transaction and commits it immediately after the query finishes.</p> <p>If you want to explicitly define transactions in your service methods that deal with reading data, you can do so by using the annotation <code>@Transactional(readOnly = true)</code>.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#why-autocommit-exists","title":"Why Autocommit Exists","text":"<ul> <li>PostgreSQL ensures that all queries are atomic, consistent, isolated, and durable (ACID properties).</li> <li>Even a <code>SELECT</code> benefits from this, as it guarantees the query operates on a consistent snapshot of the database.</li> </ul>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#why-consistency-matters-for-select-queries","title":"Why Consistency Matters for SELECT Queries","text":"<p>A snapshot in a transaction refers to the consistent view of the database that a query or set of queries operates on. Don\u2019t forget that <code>SELECT</code> operations can include complex joins across many tables.  These operations are executed as a single <code>SELECT</code> query (PostgreSQL does not split a complex join into subqueries).</p> <p>A complex join involves multiple tables and potentially millions of rows. Without a consistent snapshot, intermediate states (caused by concurrent updates, inserts, or deletes) could lead to:</p> <ul> <li>Inconsistent Results: The query might see partial updates from other transactions.</li> <li>Phantom Reads: Rows that didn\u2019t exist at the start of the query might suddenly appear due to concurrent inserts.</li> </ul> <p>Therefore, Having a consistent snapshot of the database during execution is critical for maintaining data accuracy and consistency, especially in environments with concurrent transactions.</p> <p>In the next part, we continue our curiosity-driven journey by exploring the behavior of update queries.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/","title":"PostgreSQL Transactions - Part 2","text":"<p>In part one, we explained how SELECT queries benefit from running as a transaction. In this part, let\u2019s explore why transactions are essential for UPDATE statements.</p> <p>We mentioned earlier that autocommit mode is the default in PostgreSQL. This means that if you do not explicitly use BEGIN to start a transaction, each individual SQL statement (SELECT, INSERT, UPDATE, DELETE, etc.) is treated as a separate transaction. PostgreSQL will automatically commit the statement immediately after its execution.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#importance-of-transactions-for-update-statements","title":"Importance of Transactions for UPDATE Statements","text":"<p>Running UPDATE statements as transactions is essential because modifications to a database require ACID compliance to ensure reliability and data integrity.</p> <p>When using UPDATE statements, we need to apply changes as a set of units in an all-or-nothing fashion. This is achieved through the Atomicity property of transactions. Additionally, if something goes wrong during the update, it is critical to restore the database to a valid state, ensuring data integrity. This is made possible by the Consistency property of transactions. The rollback mechanism in transactions prevents the database from being left in an invalid state due to partially completed operations.</p> <p>Moreover, we rely on the Isolation property provided by transactions. Isolation ensures that SELECT statements (and other queries) operate on a consistent view of the database, often referred to as a \"snapshot.\"</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#postgresql-isolation-levels","title":"PostgreSQL Isolation Levels","text":"<p>The default isolation level in PostgreSQL is Read Committed, which ensures that queries only see data that has been committed. However, changes made within a transaction are not visible to other transactions until the transaction is committed. This isolation level is sufficient for most applications.</p> <p>For use cases that require stricter isolation, PostgreSQL offers two higher levels:</p> <ol> <li>Repeatable Read: Provides a consistent snapshot of data for the entire duration of a transaction, preventing non-repeatable reads (when the same query returns different results due to concurrent updates).</li> <li>Serializable: The strictest isolation level, simulating sequential transaction execution. It prevents all concurrency anomalies, including phantom reads.</li> </ol>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#phantom-reads-and-isolation-challenges","title":"Phantom Reads and Isolation Challenges","text":"<p>Phantom Reads exemplify isolation challenges: - A transaction retrieves rows with <code>SELECT * FROM person WHERE age &gt; 30;</code>. - If another transaction inserts a row with <code>age = 35</code> and commits, rerunning the query would include the new row, creating a \"phantom\" effect.</p> <p>While Repeatable Read prevents some anomalies, it does not eliminate phantoms. Serializable isolation, however, ensures that even these are addressed by effectively serializing transaction execution.</p> <p>Isolation is particularly important in multi-user environments, where multiple transactions interact and can lead to complex concurrency issues.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#locking-mechanisms-outside-of-transactions","title":"Locking Mechanisms Outside of Transactions","text":"<p>Locks can also be used outside of transactions, providing manual control over database resources. For example, the LOCK TABLE statement allows users to explicitly lock a table or specific rows to manage custom workflows, independent of transactional logic.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#examples-of-row-level-locks","title":"Examples of Row-Level Locks:","text":"<ol> <li> <p><code>SELECT FOR UPDATE</code>    Locks selected rows to prevent concurrent modifications. Other transactions are blocked from updating or deleting these rows until the lock is released.</p> </li> <li> <p><code>SELECT FOR SHARE</code>    Acquires a less restrictive lock on rows, allowing other transactions to read the rows but preventing modifications. This is useful when you need to ensure rows are not updated or deleted while being processed, but without blocking other readers.</p> </li> </ol> <p>These locking mechanisms are particularly valuable for fine-tuned control over database operations in complex workflows.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#select-for-update-vs-optimistic-locking","title":"<code>SELECT FOR UPDATE</code> vs. Optimistic Locking","text":""},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#select-for-update-pessimistic-locking","title":"<code>SELECT FOR UPDATE</code> (Pessimistic Locking)","text":"<p>This approach is ideal for high-conflict scenarios, such as avoiding double-booking issues. However, it can degrade performance due to contention, as rows are locked and other transactions are blocked from modifying them until the lock is released.</p> <p>To address these limitations, optimistic locking is an alternative strategy that assumes conflicts are rare.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#optimistic-locking","title":"Optimistic Locking","text":"<p>Optimistic locking avoids locking rows during read operations, allowing other transactions to read or write to the same rows concurrently. It relies on versioning to detect conflicts at the time of committing changes.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#how-it-works","title":"How It Works:","text":"<ol> <li>A version column (or timestamp) is added to the table to track changes to rows.</li> <li>During an UPDATE, the query checks if the version column matches the expected value:<ul> <li>If the version matches, the update proceeds, and the version column is incremented.</li> <li>If the version does not match, the update fails, signaling that another transaction has modified the row, resulting in a concurrency exception.</li> </ul> </li> </ol>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#example","title":"Example:","text":"<p>Table Setup with a Version Column <pre><code>CREATE TABLE account (\n    id SERIAL PRIMARY KEY,\n    balance INT NOT NULL,\n    version INT NOT NULL\n);\n</code></pre></p> <p>Optimistic Update Query <pre><code>UPDATE account\nSET balance = 500, version = version + 1\nWHERE id = 1 AND version = 58;\n</code></pre></p> <p>If the condition <code>version = 58</code> fails (e.g., another transaction has already updated the row and incremented the version), the update will not proceed. This approach is lightweight and works best in scenarios where conflicts are infrequent, as it avoids the overhead of maintaining locks.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#practical-tips-for-transaction-management","title":"Practical Tips for Transaction Management","text":"<ol> <li> <p>Choose the Right Isolation Level</p> <ul> <li>Use Read Committed for general-purpose applications, as it balances performance and consistency.</li> <li>Opt for Repeatable Read when consistent snapshots are needed, particularly in read-heavy operations.</li> <li>Choose Serializable for scenarios requiring the highest level of data integrity, such as financial transactions, where avoiding anomalies is critical.</li> </ul> </li> <li> <p>Leverage Locking Strategically</p> <ul> <li>Use locks judiciously to maintain a balance between performance and consistency.</li> <li>For example, prefer <code>SELECT FOR UPDATE</code> in high-conflict situations to prevent double-booking or simultaneous modifications.</li> </ul> </li> <li> <p>Optimize for Concurrency</p> <ul> <li>In high-concurrency environments, favor optimistic locking to reduce contention and improve performance.</li> <li>This approach minimizes the overhead of holding locks while still ensuring consistency by checking for conflicts at commit time.</li> </ul> </li> </ol> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"design/Don%27t%20Mix%20Up%20Polling%20and%20Pooling/","title":"Don't Mix Up Polling and Pooling","text":"<p>In system design, two similar-sounding terms often cause confusion: polling and pooling. They address completely  different challenges \u2014 one deals with when to act, the other with how to manage resources.</p>"},{"location":"design/Don%27t%20Mix%20Up%20Polling%20and%20Pooling/#polling-checking-for-new-data","title":"Polling \u2014 Checking for New Data","text":"<p>Polling is when a consumer repeatedly checks if new data is available. The consumer tracks what it last saw (e.g., a timestamp or ID), then asks the producer:</p> <p>\u201cIs there anything newer than what I already have?\u201d</p> <p>If new data is available, the consumer then pulls it.</p> <ul> <li> <p>Polling vs. Pulling:</p> <ul> <li>Polling = \"Do you have anything new?\"</li> <li>Pulling = \"Okay, now give me the new thing.\"</li> </ul> </li> </ul>"},{"location":"design/Don%27t%20Mix%20Up%20Polling%20and%20Pooling/#push-the-opposite-approach","title":"Push \u2014 The Opposite Approach","text":"<p>In a push model, the producer sends new data directly to consumers whenever it becomes available.</p> <ul> <li>Push is event\u2011driven rather than time\u2011driven, often implemented using consumer webhooks. As soon as new data is ready, the producer sends it to the consumer via an HTTP POST or PUT request</li> </ul>"},{"location":"design/Don%27t%20Mix%20Up%20Polling%20and%20Pooling/#pooling-reusing-expensive-resources","title":"Pooling \u2014 Reusing Expensive Resources","text":"<p>Pooling refers to maintaining and reusing a fixed set of resources instead of creating new ones on demand. It is widely used for threads, database connections, or any object that is expensive to create and initialize.</p> <ul> <li> <p>Examples:</p> <ul> <li>Thread pool: Reuse a fixed number of threads.</li> <li>DB connection pool: Maintain live DB connections to avoid reconnecting.</li> </ul> </li> </ul> <p>Think of it as:</p> <p>\u201cDon\u2019t create a new one \u2014 grab one from the pool.\u201d</p>"},{"location":"design/Don%27t%20Mix%20Up%20Polling%20and%20Pooling/#summary","title":"Summary","text":"Term Purpose Example Polling Repeatedly check for updates Checking job status, polling a queue Pulling Retrieve data when needed Fetching new messages or records Pushing Send data as soon as it's ready Webhook or POST from server to client Pooling Reuse heavy resources Thread pool, DB connection pool <p>Happy coding! \ud83d\udcbb</p>"},{"location":"design/Don%E2%80%99t%20Mix%20Up%20Aggregates%20and%20Aggregators/","title":"Don\u2019t Mix Up Aggregates and Aggregators","text":"<p>When discussing software design, two terms that often get confused are Aggregates and Aggregators. While they may sound similar, they serve entirely different purposes. If you\u2019re working with Domain-Driven Design (DDD) or microservices, understanding this distinction is crucial.</p>"},{"location":"design/Don%E2%80%99t%20Mix%20Up%20Aggregates%20and%20Aggregators/#aggregates-a-core-ddd-concept","title":"Aggregates: A Core DDD Concept","text":"<p>In Domain-Driven Design (DDD), an Aggregate is a fundamental design practice that groups related entities and value objects into a single unit.</p> <p>Definition: A cluster of related entities treated as a single unit for data changes. Each aggregate has a root entity (aggregate root) that controls access and ensures consistency.</p>"},{"location":"design/Don%E2%80%99t%20Mix%20Up%20Aggregates%20and%20Aggregators/#key-characteristics-of-aggregates","title":"Key Characteristics of Aggregates","text":"<ol> <li>Aggregate Root: The main entity that controls access to other entities in the aggregate.</li> <li>Consistency Boundary: Ensures that changes to the aggregate maintain its integrity.</li> <li>Encapsulation: External systems interact only through the aggregate root.</li> </ol>"},{"location":"design/Don%E2%80%99t%20Mix%20Up%20Aggregates%20and%20Aggregators/#repositories-and-aggregates","title":"Repositories and Aggregates","text":"<p>Aggregates work closely with Repositories, which provide a mechanism for accessing and manipulating aggregates.</p> <ul> <li>Repositories act as collections of aggregates and handle data persistence.</li> <li>Instead of fetching individual entities, repositories return entire aggregates, ensuring that data integrity rules are respected.</li> </ul> <p>For example, in an e-commerce system, an Order Aggregate might include an <code>Order</code> entity, <code>OrderItems</code>, and a <code>ShippingInfo</code> value object. The <code>Order</code> entity would be the aggregate root, ensuring that all updates go through it.</p>"},{"location":"design/Don%E2%80%99t%20Mix%20Up%20Aggregates%20and%20Aggregators/#aggregators-a-microservices-pattern","title":"Aggregators: A Microservices Pattern","text":"<p>On the other hand, Aggregators belong to the world of microservices and are used for composing data from multiple services.</p> <p>Definition: An Aggregator is a microservice pattern used to collect and combine data from multiple services into a single response.</p>"},{"location":"design/Don%E2%80%99t%20Mix%20Up%20Aggregates%20and%20Aggregators/#key-characteristics-of-aggregators","title":"Key Characteristics of Aggregators","text":"<ol> <li>Data Composition: Aggregators fetch data from different services and merge it.</li> <li>API Gateway Role: Often act as an API facade, reducing multiple client calls.</li> <li>Read Optimization: Helps improve response times by structuring data efficiently.</li> </ol> <p>For instance, in a hotel booking system, an Aggregator Service might gather data from separate services like: - A Room Availability Service - A Pricing Service - A Customer Reviews Service</p> <p>Instead of forcing the client to call each service separately, the aggregator fetches and composes the data, returning a unified response.</p>"},{"location":"design/Don%E2%80%99t%20Mix%20Up%20Aggregates%20and%20Aggregators/#the-key-difference","title":"The Key Difference","text":"Feature Aggregates (DDD) Aggregators (Microservices) Purpose Ensures consistency and integrity of domain models Composes data from multiple microservices Scope Used within a bounded context in DDD Used at the service layer in microservices Persistence Managed via Repositories No direct persistence; just fetches and merges data Data Flow Focuses on transactional consistency Focuses on read-side optimization Example An Order Aggregate ensures all order-related changes follow business rules A Booking Aggregator merges room, pricing, and review data into one response"},{"location":"design/Don%E2%80%99t%20Mix%20Up%20Aggregates%20and%20Aggregators/#conclusion","title":"Conclusion","text":"<p>Mixing up Aggregates and Aggregators can lead to confusion in both design and communication. If you\u2019re building domain models, think Aggregates. If you\u2019re composing data from multiple services, think Aggregators.</p> <p>Understanding this distinction can help you make better architectural decisions and communicate more effectively with your team. \ud83d\ude80</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/","title":"Correlating Bamboo Concepts with AWS ECS","text":"<p>When managing CI/CD pipelines with Atlassian Bamboo and deploying containerized workloads using AWS Elastic Container Service (ECS), understanding how their concepts align can help streamline workflows. This post explores how Bamboo and ECS can complement each other, enabling parallel usage for seamless integration of CI/CD and container orchestration.</p>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#atlassian-bamboo-concepts","title":"Atlassian Bamboo Concepts","text":"<ol> <li> <p>Project    A project in Bamboo is a logical grouping of plans, representing a high-level entity such as an application, service, or product.    Example: For a \"Payment System,\" the project might include multiple plans for backend, frontend, and database components.</p> </li> <li> <p>Plan    A plan is a sequence of jobs that define how your code is built, tested, and packaged. This forms the foundation of Bamboo\u2019s CI pipeline.    Example: A backend plan could involve steps to compile Java code, run unit tests, and package it into a JAR file.</p> </li> <li> <p>Deployment    Deployment in Bamboo refers to delivering an application or artifact (produced by a plan) to a specific environment, such as development, staging, or production.    Example: A deployment plan outlines the steps for deploying the application to a staging environment, including configuration changes.</p> </li> <li> <p>Release    A release is a versioned snapshot of your software, ready for deployment. It represents a stable build after passing tests.    Example: Version <code>1.0.0</code> of your application is tagged as a release and marked as ready for production.</p> </li> </ol>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#mapping-bamboo-concepts-to-aws-ecs-for-parallel-usage","title":"Mapping Bamboo Concepts to AWS ECS for Parallel Usage","text":"<p>While Bamboo manages CI/CD workflows, AWS ECS focuses on container orchestration. These tools can work together, with Bamboo feeding ECS through seamless CI/CD pipelines. Here's how their concepts align:</p> <ol> <li> <p>Project \u2192 ECS Cluster or Application Group    A Bamboo project can correspond to an ECS cluster or a grouping of services within your infrastructure.    Example: The \"Payment System\" project in Bamboo maps to an ECS cluster hosting multiple services.</p> </li> <li> <p>Plan \u2192 ECS Task Definition    Bamboo plans can handle the CI pipeline for building and packaging Docker containers, which are then referenced in ECS task definitions.    Example: A Bamboo plan builds a Docker container and pushes it to Amazon ECR, ready for deployment in ECS.</p> </li> <li> <p>Deployment \u2192 ECS Service Update    Bamboo deployments can trigger ECS service updates, rolling out new versions of containers to specific environments like staging or production.    Example: A Bamboo deployment task updates the ECS service with a new task definition.</p> </li> <li> <p>Release \u2192 Docker Image Version or Task Definition Revision    Bamboo releases can represent versioned Docker images or ECS task definition revisions, providing stability and consistency.    Example: A release like <code>payment-backend:1.0.0</code> is tagged in Bamboo and used as a task definition in ECS.</p> </li> </ol>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#configuring-bamboo-plans-using-iac-with-java","title":"Configuring Bamboo Plans Using IaC with Java","text":"<p>Bamboo allows plans to be defined and managed programmatically using Infrastructure as Code (IaC). This approach ensures consistency, repeatability, and easier integration with version control systems. As of now, Atlassian Bamboo supports Java (via the Bamboo Specs API) and YAML (for declarative configurations).</p>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#example-defining-a-bamboo-plan-with-java","title":"Example: Defining a Bamboo Plan with Java","text":"<pre><code>// Initialize Bamboo Server\nBambooServer bambooServer = new BambooServer(\"https://your-bamboo-server.com\");\n\n// Create the Bamboo Plan\nPlan plan = new Plan(\n    new Project().key(\"DOCKER\").name(\"Docker Project\"),\n    \"Docker Image Build Plan\",\n    \"DIB\")\n    .description(\"Plan to build Docker images for ECS deployment\")\n    .stages(\n        new Stage(\"Build Stage\")\n            .jobs(new Job(\"Build and Dockerize Job\", \"BUILD\")\n                .tasks(\n                    // Step 1: Checkout the source code\n                    new VcsCheckoutTask()\n                        .description(\"Checkout Code\")\n                        .checkoutItems(new CheckoutItem().repository(\"MyRepo\")),\n\n                    // Step 2: Build the application (e.g., Maven build)\n                    new ScriptTask()\n                        .description(\"Build Application\")\n                        .inlineBody(\"mvn clean install\"),\n\n                    // Step 3: Build the Docker image\n                    new DockerBuildImageTask()\n                        .description(\"Build Docker Image\")\n                        .imageName(\"my-ecr-repo/my-app:latest\")\n                        .dockerfileInWorkingDir()\n                )\n            )\n    );\n\n// Publish the plan to Bamboo\nbambooServer.publish(plan);\n\nSystem.out.println(\"Plan published successfully!\");\n</code></pre>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#choosing-between-java-and-yaml","title":"Choosing Between Java and YAML","text":"Feature Java YAML Complexity Suitable for complex configurations Ideal for simple and straightforward setups Flexibility Highly flexible, supports logic and dynamic plans Limited to static declarative configurations Ease of Use Requires Java knowledge and tools Easy for non-developers to use Tooling IDE support, type checking Plain text editor is sufficient <p>For most teams, YAML is easier for basic use cases, while Java offers the power and flexibility needed for advanced configurations. This approach complements AWS ECS, where you can similarly define infrastructure using tools like AWS CloudFormation or Terraform, enabling end-to-end IaC workflows.</p>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#conclusion","title":"Conclusion","text":"<p>Using Bamboo and AWS ECS in parallel leverages the strengths of both platforms: Bamboo\u2019s robust CI/CD pipelines and ECS\u2019s efficient container orchestration. Adding IaC capabilities to Bamboo plans using Java enhances automation, consistency, and collaboration. Together, these tools empower teams to streamline workflows, scale workloads, and maintain reliable deployments across diverse environments.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/","title":"How Web Servers Handle Logging Efficiently","text":"<p>Have you ever wondered how web servers generate log files so quickly, even though writing to files is known to be an expensive operation? Logging is an essential aspect of web servers, providing critical insights into application behavior, performance, and errors. However, if every log entry triggered an immediate disk write, it would significantly slow down the server. So, how do web servers manage to write logs efficiently while maintaining high performance??</p>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#the-challenges-of-logging","title":"The Challenges of Logging","text":"<p>Writing logs to files involves disk I/O operations, which can be slow compared to in-memory operations. Additionally, excessive logging can:</p> <ul> <li>Increase latency</li> <li>Cause performance bottlenecks</li> <li>Consume significant storage space</li> <li>Lead to disk contention</li> </ul> <p>To overcome these challenges, modern web servers and logging frameworks employ various optimization techniques. Let\u2019s explore these methods.</p>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#techniques-for-fast-and-efficient-logging","title":"Techniques for Fast and Efficient Logging","text":""},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#1-buffered-writes","title":"1. Buffered Writes","text":"<p>Instead of writing each log entry immediately to the disk, logs are first accumulated in memory and then flushed to disk in batches. This reduces the number of expensive disk write operations and improves performance.</p> <p>Most logging libraries, such as Logback, Log4j, and Systemd journald, use buffered I/O to optimize performance.</p>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#2-asynchronous-logging","title":"2. Asynchronous Logging","text":"<p>Logging can be handled asynchronously, meaning log messages are placed in a queue and written to disk by a background thread. This prevents the main application thread from being blocked while waiting for the log entry to be written.</p>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#3-memory-mapped-files-mmap","title":"3. Memory-Mapped Files (MMAP)","text":"<p>Some advanced logging systems use memory-mapped files, which allow the operating system to handle file I/O efficiently without explicit disk writes from the application. This technique enables faster and more efficient log writing.</p>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#4-batching-and-log-rotation","title":"4. Batching and Log Rotation","text":"<ul> <li>Batching: Instead of writing logs line-by-line, they are written in batches to minimize I/O overhead.</li> <li>Log Rotation: Large log files can slow down a system. Log rotation ensures that old logs are compressed or archived while keeping active logs small and manageable.</li> </ul>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#5-direct-append-mode","title":"5. Direct Append Mode","text":"<p>Using the append mode (<code>O_APPEND</code> flag in Linux) allows the server to keep the log file open and directly append new entries. This reduces system calls and enhances performance.</p>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#6-write-ahead-logging-wal","title":"6. Write-Ahead Logging (WAL)","text":"<p>Some systems use write-ahead logging (WAL), where logs are first written sequentially to a log file before committing transactions. This method reduces disk seek times and ensures durability.</p>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#7-using-faster-storage-ssd-ram-disks","title":"7. Using Faster Storage (SSD, RAM Disks)","text":"<ul> <li>Writing logs to SSDs instead of traditional HDDs significantly improves performance.</li> <li>Some high-performance applications use in-memory log files (RAM disks) and periodically flush them to persistent storage.</li> </ul>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#8-centralized-log-aggregation","title":"8. Centralized Log Aggregation","text":"<p>Many modern web applications use centralized logging solutions like Fluentd, Logstash, or Loki to offload log processing. Instead of writing logs to disk, the application sends them over the network to a log collector, minimizing disk usage.</p>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#9-compression-and-binary-logging","title":"9. Compression and Binary Logging","text":"<p>Instead of writing plain text logs, some systems use binary logs or compressed logs to reduce I/O overhead. This method speeds up log writing and reduces storage costs.</p>"},{"location":"devops/How%20Web%20Servers%20Handle%20Logging%20Efficiently/#conclusion","title":"Conclusion","text":"<p>Efficient logging is crucial for maintaining web server performance. By implementing techniques like buffered writes, asynchronous logging, memory-mapped files, and log aggregation, servers can handle high log volumes without significant performance degradation.</p> <p>Understanding and leveraging these strategies can help developers optimize their logging mechanisms, ensuring that performance remains robust even under heavy workloads.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/","title":"Using Nginx to Front Both Backend and Frontend","text":"<p>When setting up a web application with a Spring Boot backend and a React frontend, you can choose to deploy them directly or use Nginx as a reverse proxy. Both options are viable, but using Nginx offers several advantages, especially for production environments.</p>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#1-without-nginx-direct-setup","title":"1. Without Nginx: Direct Setup","text":"<p>In this scenario, the backend and frontend are served directly to clients on their respective ports:</p> <ul> <li>Frontend URL: <code>http://localhost:4200</code> (React)</li> <li>Backend URL: <code>http://localhost:8085</code> (Spring Boot)</li> </ul>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#pros","title":"Pros:","text":"<ul> <li>Simplicity: No need for additional tools or configuration.</li> <li>Direct Access: Requests go straight to the backend or frontend, minimizing latency.</li> </ul>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#cons","title":"Cons:","text":"<ul> <li>CORS Issues: Since frontend (React) and backend (Spring Boot) are hosted on different origins, you'll need to configure CORS in Spring Boot. This adds complexity and potential security risks. </li> </ul> <p>Note: An origin is defined by the combination of the protocol, host, and port. Therefore, the URLs above are considered different origins because the ports (4200 vs. 8085) differ, even though the protocol and host are the same.</p>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#handling-cors-in-spring-boot","title":"Handling CORS in Spring Boot","text":"<p>Spring Boot provides the <code>@CrossOrigin</code> annotation, which allows fine-grained control over cross-origin resource sharing. Here\u2019s an example of how to configure a specific controller to handle CORS requests:</p> <pre><code>@CrossOrigin\n@RestController\n@RequestMapping(\"/account\")\npublic class AccountController {\n\n    @GetMapping(\"/{id}\")\n    public Account retrieve(@PathVariable Long id) {\n        // Fetch account details\n        return new Account(); // Example logic\n    }\n}\n</code></pre>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#explanation","title":"Explanation:","text":"<ol> <li><code>@CrossOrigin</code>: This annotation, when used with its default configuration, enables cross-origin requests for all origins.</li> <li>Controller-level CORS Configuration: You can apply this annotation to individual methods or at the class level for all endpoints within the controller.</li> <li>Methods Supported: In the example, both <code>GET</code> and <code>DELETE</code> requests are exposed for CORS handling.</li> </ol> <p>While this approach is effective, it requires specifying the allowed origins manually and might not scale well for dynamic environments.</p>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#2-with-nginx-reverse-proxy-setup","title":"2. With Nginx: Reverse Proxy Setup","text":"<p>Using Nginx as a reverse proxy creates a unified entry point for both services. Nginx routes requests based on their paths:</p> <ul> <li>Frontend URL: <code>http://localhost:9002</code> (Served through Nginx)</li> <li>Backend API: <code>http://localhost:9002/api</code></li> </ul>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#pros_1","title":"Pros:","text":"<ul> <li>Unified Access Point: Both services are accessible on the same port. For example:<ul> <li><code>/</code> serves the React app.</li> <li><code>/api/*</code> routes to the Spring Boot backend.</li> </ul> </li> <li>Avoid CORS Issues: Since Nginx proxies requests internally, the frontend and backend appear as a single origin.</li> <li>SSL Termination: Nginx can handle HTTPS traffic, enhancing security in production.</li> <li>Load Balancing: Distributes traffic among multiple instances of your backend or frontend.</li> <li>Static Content Caching: Speeds up static file delivery and reduces backend load.</li> <li>Enhanced Security: Supports rate limiting, IP filtering, and other protective measures.</li> </ul>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#example-nginx-configuration","title":"Example Nginx Configuration","text":"<p>Here\u2019s a sample <code>Nginx.conf</code> for routing requests to the frontend and backend:</p> <pre><code>server {\n    listen 80;\n\n    # Route requests for the React frontend\n    location / {\n        proxy_pass http://localhost:4200;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n\n    # Route API requests to the Spring Boot backend\n    location /api/ {\n        proxy_pass http://localhost:8085;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n}\n</code></pre>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#conclusion","title":"Conclusion","text":"<ul> <li>Without Nginx: Best for local development or simple setups where CORS issues can be managed, and scalability isn\u2019t a concern.</li> <li>With Nginx: Ideal for production environments requiring unified access, better security, and scalability.</li> </ul> <p>Whether you choose to go with or without Nginx depends on your specific use case, but understanding how to handle CORS is essential for smooth backend and frontend communication. Let me know if you\u2019d like to dive deeper into any aspect of this configuration!</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/Concurrency%20-%20Part%201/","title":"Concurrency - Part 1","text":"<p>When building concurrent applications in Java, managing threads properly is crucial. Spawning raw threads (<code>new Thread(...)</code>) works for simple cases, but it's inefficient and hard to scale. Java\u2019s concurrency package offers a more powerful approach: thread pools.</p> <p>This post will walk you through the fundamentals of using <code>ExecutorService</code> and customizing threads with <code>ThreadFactory</code>.  Then we\u2019ll explore <code>ForkJoinPool.commonPool()</code> as a special thread pool designed mainly for short, CPU-bound tasks.</p>"},{"location":"java/Concurrency%20-%20Part%201/#why-use-thread-pools","title":"Why Use Thread Pools?","text":"<p>Thread pools reuse threads instead of creating new ones for each task. This means:</p> <ul> <li>Better performance (less time creating/destroying threads)</li> <li>Controlled concurrency (limits how many threads run at once)</li> <li>Cleaner code (no manual thread lifecycle management)</li> </ul>"},{"location":"java/Concurrency%20-%20Part%201/#using-executorservice","title":"Using <code>ExecutorService</code>","text":"<p><code>ExecutorService</code> is the most common way to use thread pools in Java:</p> <pre><code>import java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class PoolExample {\n    public static void main(String[] args) {\n        ExecutorService executor = Executors.newFixedThreadPool(2);\n\n        executor.submit(() -&gt; {\n            System.out.println(\"Task 1 executed by \" + Thread.currentThread().getName());\n        });\n\n        executor.submit(() -&gt; {\n            System.out.println(\"Task 2 executed by \" + Thread.currentThread().getName());\n        });\n\n        executor.shutdown();\n    }\n}\n</code></pre> <p>\u2611\ufe0f You can choose from:</p> <ul> <li><code>newFixedThreadPool(int n)</code></li> <li><code>newCachedThreadPool()</code></li> <li><code>newSingleThreadExecutor()</code></li> </ul> <p>Each comes with trade-offs depending on your workload (CPU-bound, I/O-bound, etc.).</p>"},{"location":"java/Concurrency%20-%20Part%201/#customizing-threads-with-threadfactory","title":"Customizing Threads with <code>ThreadFactory</code>","text":"<p>Need more control over thread naming or daemon settings? Use a <code>ThreadFactory</code>.</p> <pre><code>import java.util.concurrent.ThreadFactory;\n\nThreadFactory factory = r -&gt; {\n    Thread t = new Thread(r);\n    t.setName(\"worker-\" + t.getId());\n    return t;\n};\n</code></pre> <p>You can pass this factory into your executor:</p> <pre><code>ExecutorService executor = Executors.newFixedThreadPool(2, factory);\n</code></pre> <p>This is super helpful for debugging and log tracing.</p>"},{"location":"java/Concurrency%20-%20Part%201/#concurrency-vs-parallelism","title":"Concurrency vs. Parallelism","text":"<p>Before we go further, it's important to understand the difference between concurrency and parallelism. </p> <ul> <li>Parallelism means using multiple CPU cores to execute tasks at the same time. </li> <li>Concurrency, on the other hand, is about handling multiple tasks at once\u2014usually on a single core\u2014by switching between  them efficiently. It gives the impression of things happening simultaneously, even if they\u2019re not.</li> </ul> <p>Although you can achieve a degree of parallelism using an <code>ExecutorService</code> (for example, by creating a fixed thread pool  with <code>Executors.newFixedThreadPool()</code> on a multi-core machine), its primary purpose is to manage task submission and  scheduling. It was designed for general-purpose task execution (particularly well-suited for I/O-bound workloads). </p> <p>If you're aiming for fine-grained, CPU-bound parallelism (along with advanced features like task splitting and work-stealing), then <code>ForkJoinPool</code> is exactly what you're looking for.</p>"},{"location":"java/Concurrency%20-%20Part%201/#what-is-forkjoinpoolcommonpool","title":"What is <code>ForkJoinPool.commonPool()</code>?","text":"<p>This is a special shared thread pool that is used by:</p> <ul> <li><code>parallelStream()</code></li> <li><code>CompletableFuture.runAsync()</code> and <code>supplyAsync()</code> (when no custom executor is provided)</li> <li>Fork/Join Framework (e.g., <code>RecursiveTask</code>, <code>RecursiveAction</code>)</li> </ul> <p>Although <code>ForkJoinPool.commonPool()</code> is primarily designed for parallelism, it also incorporates concurrency.</p> <ul> <li> <p>Parallelism: <code>ForkJoinPool.commonPool()</code> utilizes multiple worker threads\u2014typically backed by available CPU cores\u2014to execute tasks in parallel. The default parallelism level is usually <code>Runtime.getRuntime().availableProcessors() - 1</code>, meaning it takes advantage of multiple cores to run tasks simultaneously.</p> </li> <li> <p>Concurrency: Beyond parallel execution, the pool handles task scheduling, load balancing through work-stealing, and efficient queuing. This dynamic task management is a hallmark of concurrency\u2014coordinating multiple tasks over time, even if they're not all executing at once.</p> </li> </ul> <p>By default, the size of the common <code>ForkJoinPool</code> is set to <code>Runtime.getRuntime().availableProcessors() - 1</code>. This configuration reserves one core for the main thread and allows the remaining worker threads to fully utilize the system\u2019s CPU capacity. Let\u2019s see how this works on an 8-core machine in the example below:</p> <pre><code>import java.util.Arrays;\nimport java.util.List;\n\npublic class ParallelStreamExample {\n    public static void main(String[] args) {\n\n        // Prints: 8\n        System.out.println(\"Available processors (cores): \" + Runtime.getRuntime().availableProcessors());\n\n        List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\n\n        // Use parallelStream to process the list in parallel\n        int sum = numbers.parallelStream()\n                // This method is used to perform an action on each element of the stream as it is processed. \n                // It does not affect the result of the stream, but it's useful for debugging or logging.\n                .peek(num -&gt; System.out.println(\"Processing \" + num + \" on thread: \" + Thread.currentThread().getName()))\n                .mapToInt(Integer::intValue)\n                .sum();\n\n        System.out.println(\"Sum: \" + sum);\n    }\n}\n</code></pre> <ul> <li>It prints something like:</li> </ul> <pre><code>Processing 5 on thread: ForkJoinPool.commonPool-worker-5\nProcessing 7 on thread: main\nProcessing 2 on thread: ForkJoinPool.commonPool-worker-3\nProcessing 3 on thread: ForkJoinPool.commonPool-worker-1\nProcessing 9 on thread: ForkJoinPool.commonPool-worker-2\nProcessing 4 on thread: ForkJoinPool.commonPool-worker-6\nProcessing 6 on thread: ForkJoinPool.commonPool-worker-4\nProcessing 1 on thread: ForkJoinPool.commonPool-worker-7\nProcessing 8 on thread: ForkJoinPool.commonPool-worker-5\nProcessing 10 on thread: main\nSum: 55\n</code></pre>"},{"location":"java/Concurrency%20-%20Part%201/#when-to-avoid-it","title":"When to Avoid It","text":"<p>The <code>ForkJoinPool.commonPool()</code> is designed for non-blocking, CPU-bound tasks. You should not use it for blocking I/O or long-running tasks, because:</p> <ul> <li>It has a limited number of threads</li> <li>If all threads are blocked, other tasks will starve</li> </ul> <p>For example, if you have blocking or long-running processes, you should avoid using the default executor of <code>CompletableFuture.supplyAsync()</code>. Instead, you should provide your own <code>ExecutorService</code>, like this:</p> <pre><code>CompletableFuture.supplyAsync(() -&gt; slowOperation(), customExecutor);\n</code></pre> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/Concurrency%20-%20Part%202/","title":"Concurrency - Part 2","text":"<p>In part one, we explored how to manage thread pools in Java using <code>ExecutorService</code> and how that  helps you write scalable, concurrent applications. In this post, we look at how Apache Tomcat, a popular Java HTTP  server, uses thread pools internally to manage concurrent HTTP requests.</p>"},{"location":"java/Concurrency%20-%20Part%202/#why-thread-pools-matter-in-web-servers","title":"Why Thread Pools Matter in Web Servers","text":"<p>When dealing with HTTP servers, thread pools are crucial for enabling efficient request handling. If a server created a  brand-new thread for every request, the overhead would be massive \u2014 not to mention unstable under load.</p> <p>Instead, servers like Tomcat use a thread pool, which reuses a fixed number of threads to handle incoming requests  concurrently.</p>"},{"location":"java/Concurrency%20-%20Part%202/#thread-pooling","title":"Thread Pooling","text":"<p>Tomcat maintains a pool of threads ready to process HTTP requests. When a request arrives:</p> <ol> <li>It\u2019s handed off to an available thread from the pool.</li> <li>The request is processed (e.g., your Spring controller runs).</li> <li>The response is sent.</li> <li>The thread is returned to the pool.</li> </ol> <p>This reuse avoids the cost of creating/destroying threads on every request. By reusing threads, Tomcat can  handle hundreds of concurrent requests while keeping resource usage in check.</p>"},{"location":"java/Concurrency%20-%20Part%202/#configuring-thread-pool-in-spring-boot","title":"Configuring Thread Pool in Spring Boot","text":"<p>If you\u2019re using Spring Boot with embedded Tomcat, you can configure the thread pool using <code>application.properties</code>:</p> <pre><code># Maximum number of worker threads\nserver.tomcat.max-threads=200\n\n# Minimum number of idle (spare) threads kept alive\nserver.tomcat.min-spare-threads=10\n</code></pre> <p>For advanced tuning (like <code>max-spare-threads</code>), you can customize it programmatically using a <code>TomcatConnectorCustomizer</code>.</p>"},{"location":"java/Concurrency%20-%20Part%202/#thread-lifecycle-in-tomcat","title":"Thread Lifecycle in Tomcat","text":"<ul> <li>On startup, Tomcat creates the number of threads specified by <code>minSpareThreads</code>.</li> <li>As requests increase, more threads are created (up to <code>maxThreads</code>).</li> <li>If threads are idle and the number exceeds <code>maxSpareThreads</code>, Tomcat starts shutting them down to save memory.</li> </ul> <p>This dynamic scaling keeps your server responsive without over-allocating resources.</p>"},{"location":"java/Concurrency%20-%20Part%202/#logging-thread-id-in-spring-mvc","title":"Logging Thread ID in Spring MVC","text":"<p>If you want to see which thread is handling each request in your Spring Boot app, you can implement a  simple <code>HandlerInterceptor</code> like this:</p> <pre><code>import jakarta.servlet.http.HttpServletRequest;\nimport jakarta.servlet.http.HttpServletResponse;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.web.servlet.HandlerInterceptor;\n\npublic class ThreadLogger implements HandlerInterceptor {\n\n    private static final Logger log = LoggerFactory.getLogger(ThreadLogger.class);\n\n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)\n        throws Exception {\n        log.info(\"Thread ID preHandle: {}\", Thread.currentThread().getId());\n        return true;\n    }\n}\n</code></pre> <p>When you make requests to the server, your logs might look like this:</p> <pre><code>2025-04-06 10:12:01.124  INFO 22544 --- [http-nio-8080-exec-1] c.e.d.ThreadLogger : Thread ID preHandle: 27\n2025-04-06 10:12:01.126  INFO 22544 --- [http-nio-8080-exec-2] c.e.d.ThreadLogger : Thread ID preHandle: 30\n2025-04-06 10:12:01.128  INFO 22544 --- [http-nio-8080-exec-3] c.e.d.ThreadLogger : Thread ID preHandle: 35\n</code></pre> <p>This shows that each HTTP request was picked up by a different worker thread from the pool.</p>"},{"location":"java/Concurrency%20-%20Part%202/#takeaway","title":"Takeaway","text":"<p>Tomcat does not spawn a thread per request. Instead, it:</p> <ul> <li>Uses a thread pool to handle requests efficiently</li> <li>Allows configuration of concurrency limits</li> <li>Scales based on load and resource availability</li> </ul> <p>This architecture is what makes Tomcat suitable for production-scale applications \u2014 and it\u2019s another reason why understanding thread pools is essential for backend developers.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/Concurrency%20-%20Part%203/","title":"Concurrency - Part 3","text":"<p>Modern Java applications often need to perform multiple tasks asynchronously without blocking threads or slowing down the system. One of the essential tools introduced in Java 8 to address this need is the <code>CompletableFuture</code>.</p> <p>This blog post focuses on how <code>CompletableFuture</code> makes asynchronous programming easier, compared with JavaScript\u2019s Promise concept, and demonstrates its real-world use in a Java application.</p>"},{"location":"java/Concurrency%20-%20Part%203/#how-completablefuture-compares-to-javascripts-promise","title":"How CompletableFuture Compares to JavaScript's Promise","text":"<p>If you're familiar with JavaScript Promises, understanding <code>CompletableFuture</code> becomes much easier:</p> Aspect JavaScript Promise Java CompletableFuture Creating Async Operation <code>new Promise((resolve, reject) =&gt; {...})</code> <code>CompletableFuture.supplyAsync(() -&gt; {...})</code> Handling Result <code>.then(value =&gt; {...})</code> <code>.thenAccept(result -&gt; {...})</code> Handling Errors <code>.catch(error =&gt; {...})</code> <code>.exceptionally(error -&gt; {...})</code> Execution Context Event loop, non-blocking Separate thread pool (e.g., ForkJoinPool or ExecutorService) Blocking Behavior Non-blocking by design Supports both non-blocking and blocking (<code>get()</code>) <p>\u2705 <code>CompletableFuture</code> brings Promise-style async composition into Java, with even more control over threading.</p>"},{"location":"java/Concurrency%20-%20Part%203/#basic-examples","title":"Basic Examples","text":"<p>Let's look at two simple cases: <code>runAsync</code> and <code>supplyAsync</code>. Use <code>runAsync</code> when you don't need a result, and <code>supplyAsync</code> when you do.</p>"},{"location":"java/Concurrency%20-%20Part%203/#example-1-runasync-task-without-a-return-value","title":"Example 1: <code>runAsync</code> \u2014 Task without a return value","text":"<p><pre><code>import java.util.concurrent.CompletableFuture;\n\npublic class RunAsyncExample {\n    public static void main(String[] args) {\n        System.out.println(\"Main thread: \" + Thread.currentThread().getName());\n\n        CompletableFuture&lt;Void&gt; future = CompletableFuture.runAsync(() -&gt; \n                System.out.println(\"Running async task on: \" + Thread.currentThread().getName()));\n\n        future.join();\n    }\n}\n</code></pre> Output might look like: <pre><code>Main thread: main\nRunning async task on: ForkJoinPool.commonPool-worker-1\n</code></pre></p>"},{"location":"java/Concurrency%20-%20Part%203/#example-2-supplyasync-task-with-a-return-value","title":"Example 2: <code>supplyAsync</code> \u2014 Task with a return value","text":"<p><pre><code>import java.util.concurrent.CompletableFuture;\n\npublic class SupplyAsyncExample {\n    public static void main(String[] args) {\n        CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt;\n                \"Hello from \" + Thread.currentThread().getName());\n\n        String result = future.join();\n        System.out.println(\"Result: \" + result);\n    }\n}\n</code></pre> Output might look like: <pre><code>Result: Hello from ForkJoinPool.commonPool-worker-1\n</code></pre></p>"},{"location":"java/Concurrency%20-%20Part%203/#real-world-usage-asynchronous-file-import","title":"Real-World Usage: Asynchronous File Import","text":"<p>Let's see a real-world example: handling asynchronous file imports without blocking HTTP request threads.</p> <p>Note: The async behavior here is achieved using <code>@Async</code>, which runs on Spring's default async executor (like <code>SimpleAsyncTaskExecutor</code>) \u2014 not on <code>ForkJoinPool.commonPool()</code>. The method returns <code>CompletableFuture&lt;String&gt;</code>, meaning it behaves similarly to <code>supplyAsync</code>, where a result (<code>jobId</code>) is asynchronously produced and returned.</p>"},{"location":"java/Concurrency%20-%20Part%203/#service-layer-importservice","title":"Service Layer: ImportService","text":"<pre><code>@Async\npublic CompletableFuture&lt;String&gt; importFile(String jobId, String filePath) {\n    try {\n        HSSFWorkbook workbook = new HSSFWorkbook(new FileInputStream(filePath));\n        HSSFSheet sheet = workbook.getSheetAt(0);\n\n        if (sheet.getPhysicalNumberOfRows() &gt; 1) {\n            processSheetRows(sheet, jobId);\n        }\n\n        return CompletableFuture.completedFuture(jobId);\n\n    } catch (Exception e) {\n        throw new JobException(jobId, e.getMessage());\n    }\n}\n</code></pre> <ul> <li><code>@Async</code> ensures the method runs in a background thread.</li> <li>Returns <code>CompletableFuture&lt;String&gt;</code>, behaving like a <code>supplyAsync</code>.</li> <li>Uses Spring Boot\u2019s default async executor, not ForkJoinPool.</li> </ul>"},{"location":"java/Concurrency%20-%20Part%203/#controller-layer-fileimportcontroller","title":"Controller Layer: FileImportController","text":"<pre><code>@PostMapping\npublic ResponseEntity&lt;JobIdResponse&gt; importFile(@RequestParam(\"file\") MultipartFile file) throws IOException {\n    File uploadedFile = fileStorageService.saveFile(file);\n    String filePath = uploadedFile.getAbsolutePath();\n    Job newJob = jobService.saveNewFileJob(JobType.IMPORT);\n\n    importService.importFile(newJob.getId(), filePath)\n                 .whenComplete(fileImportServiceCallback);\n\n    return ResponseEntity.status(HttpStatus.CREATED).body(JobMapper.toJobId(newJob));\n}\n</code></pre> <ul> <li>Saves the uploaded file.</li> <li>Triggers <code>importFile</code> asynchronously.</li> <li>Registers a <code>whenComplete</code> callback to react to completion.</li> <li>Returns HTTP 201 (Created) immediately, without waiting for import to finish.</li> </ul>"},{"location":"java/Concurrency%20-%20Part%203/#callback-handling-fileservicecallback","title":"Callback Handling: FileServiceCallback","text":"<pre><code>@Component\n@RequiredArgsConstructor\npublic class FileServiceCallback implements BiConsumer&lt;String, Throwable&gt; {\n\n    private final JobService jobService;\n\n    @Override\n    public void accept(String jobId, Throwable ex) {\n        if (ex == null) {\n            jobService.updateJobState(jobId, JobState.DONE);\n        } else {\n            jobService.updateJobState(jobId, JobState.ERROR);\n        }\n    }\n}\n</code></pre> <ul> <li>If the import is successful \u2192 mark job as <code>DONE</code>.</li> <li>If it fails \u2192 mark job as <code>ERROR</code>.</li> </ul>"},{"location":"java/Concurrency%20-%20Part%203/#key-takeaways","title":"Key Takeaways","text":"<ul> <li><code>CompletableFuture</code> enables easy asynchronous programming.</li> <li><code>runAsync</code> is for tasks without a return; <code>supplyAsync</code> is for tasks with a return.</li> <li>Returning <code>CompletableFuture&lt;T&gt;</code> manually (like with <code>completedFuture</code>) is a common pattern when you already have a value.</li> <li>Using <code>@Async</code> with <code>CompletableFuture</code> provides clean, scalable non-blocking designs.</li> <li>In Spring, <code>@Async</code> uses its own executor, not the ForkJoinPool by default.</li> </ul> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/Concurrency%20-%20Part%204/","title":"Concurrency - Part 4","text":"<p>As applications demand higher scalability, non-blocking I/O, and minimal thread usage, these traditional models start to show limitations. This is where reactive programming enters the scene\u2014not as a replacement, but as a fundamentally different approach to concurrency.</p> <p>In this post, we\u2019ll dive into reactive concurrency in Java with Project Reactor and explore how it transforms the way we handle asynchronous, concurrent tasks\u2014especially in high-throughput systems.</p>"},{"location":"java/Concurrency%20-%20Part%204/#reactive-vs-imperative-concurrency","title":"Reactive vs. Imperative Concurrency","text":"Feature Imperative Model (Threads, Executors) Reactive Model (Project Reactor) Execution control You manage when and how threads run You describe what should happen, not how Blocking Often blocking (e.g., thread waits) Non-blocking, event-driven Thread usage One thread per task (virtual threads improve this) Small thread pool, I/O multiplexing Backpressure Manual, if at all Built-in flow control <p>Reactive programming focuses on declarative concurrency\u2014you define a pipeline of operations, and the system executes them asynchronously and concurrently behind the scenes.</p>"},{"location":"java/Concurrency%20-%20Part%204/#project-reactor-a-reactive-concurrency-engine","title":"Project Reactor: A Reactive Concurrency Engine","text":"<p>Project Reactor brings reactive streams to Java. Instead of managing threads, queues, and futures, you work with two key abstractions:</p> <ul> <li><code>Mono&lt;T&gt;</code>: A publisher of zero or one item.</li> <li><code>Flux&lt;T&gt;</code>: A publisher of zero to many items (a reactive stream).</li> </ul> <p>These types form the backbone of reactive pipelines, offering powerful operators and built-in support for concurrency and error handling.</p>"},{"location":"java/Concurrency%20-%20Part%204/#threading-in-reactor-with-schedulers","title":"Threading in Reactor with Schedulers","text":"<p>In reactive programming, execution doesn't happen immediately in the calling thread. Instead, Reactor uses Schedulers to control where and how tasks run, allowing better separation of concerns and optimal use of system resources.</p> Scheduler Common Use Case <code>Schedulers.parallel()</code> CPU-bound tasks (e.g., data crunching) <code>Schedulers.boundedElastic()</code> Blocking I/O (e.g., file or DB access) <code>Schedulers.single()</code> Work that must run on a single thread <code>Schedulers.immediate()</code> Execute directly on the current thread"},{"location":"java/Concurrency%20-%20Part%204/#example-parallel-processing-without-threads","title":"Example: Parallel Processing without Threads","text":"<pre><code>Flux.range(1, 10)\n    .flatMap(i -&gt; Mono.just(i)\n          .subscribeOn(Schedulers.parallel())\n          .map(this::process))\n    .collectList()\n    .block();\n</code></pre> <p>Here, <code>flatMap</code> handles parallelism, and <code>subscribeOn</code> ensures each task runs concurrently\u2014without you ever creating a thread.</p>"},{"location":"java/Concurrency%20-%20Part%204/#built-in-backpressure-controlled-concurrency","title":"Built-in Backpressure = Controlled Concurrency","text":"<p>Reactive streams (and Project Reactor) support backpressure, a critical feature absent in models like <code>CompletableFuture</code>. Backpressure allows the consumer to control the rate of data flow, preventing memory overload or CPU exhaustion.</p> <p>This makes reactive pipelines self-regulating, especially in systems that process data continuously or unevenly (e.g., stream ingestion, APIs, or message queues).</p>"},{"location":"java/Concurrency%20-%20Part%204/#integrating-reactive-concurrency-with-spring","title":"Integrating Reactive Concurrency with Spring","text":"<p>To build fully non-blocking applications in the Spring ecosystem, you can combine Project Reactor with:</p> <ul> <li>Spring WebFlux: A reactive web framework.</li> <li>Spring Data R2DBC: A reactive relational database integration.</li> </ul>"},{"location":"java/Concurrency%20-%20Part%204/#reactive-repository-interface","title":"Reactive Repository Interface:","text":"<pre><code>public interface PersonRepository extends ReactiveCrudRepository&lt;Person, Long&gt; {\n    Flux&lt;Person&gt; findAll();\n    Mono&lt;Person&gt; findById(Long id);\n}\n</code></pre> <p>Unlike blocking repositories, this interface returns <code>Flux</code> and <code>Mono</code>, fully integrated with Reactor and WebFlux for end-to-end reactive pipelines.</p>"},{"location":"java/Concurrency%20-%20Part%204/#project-reactor-vs-nodejs-a-conceptual-parallel","title":"Project Reactor vs. Node.js: A Conceptual Parallel","text":"<p>Reactive programming isn\u2019t unique to Java. Node.js has long used event loops and non-blocking I/O. Reactor brings similar principles to the JVM with stronger type safety and backpressure:</p> Concept Project Reactor Node.js Async Type <code>Mono</code>, <code>Flux</code> Promises, Streams Execution Scheduler-based Event loop Backpressure \u2705 Built-in \u26a0\ufe0f Rudimentary Stream control Functional operators Streams with <code>pause()/resume()</code> Integration Spring WebFlux, R2DBC Express, native modules"},{"location":"java/Concurrency%20-%20Part%204/#when-to-go-reactive","title":"When to Go Reactive","text":"<p>\u2705 Choose reactive concurrency when your application must:</p> <ul> <li> <p>Handle a high volume of concurrent I/O (e.g., HTTP APIs, messaging)</p> </li> <li> <p>Support streaming or real-time data pipelines</p> </li> <li> <p>Scale with fewer threads and predictable resource usage</p> </li> </ul> <p>\u274c Avoid it when:</p> <ul> <li> <p>You need synchronous, CPU-heavy workflows</p> </li> <li> <p>Your team isn\u2019t familiar with functional or stream-based programming</p> </li> <li> <p>You\u2019re working with libraries that aren\u2019t reactive-compatible</p> </li> </ul>"},{"location":"java/Concurrency%20-%20Part%204/#how-does-the-project-reactor-relate-to-completablefuture","title":"How does the Project Reactor relate to CompletableFuture?","text":"<p>CompletableFuture:</p> <ul> <li> <p>Part of Java\u2019s standard library (introduced in Java 8).</p> </li> <li> <p>Represents a single future result of an asynchronous computation.</p> </li> <li> <p>Provides a straightforward API to handle asynchronous tasks and their results.</p> </li> <li> <p>Does not implement the Reactive Streams specification. It is more focused on individual, one-time asynchronous tasks   rather than streams of data.</p> </li> <li> <p>Supports chaining of asynchronous operations through methods like thenApply, thenAccept, thenCompose, etc.</p> </li> </ul> <p>Project Reactor:</p> <ul> <li> <p>A library that implements the Reactive Streams specification and provides a powerful API for reactive programming.</p> </li> <li> <p>Offers two main types: Mono (for zero or one result) and Flux (for zero or more results).</p> </li> <li> <p>Designed for building non-blocking, event-driven applications.</p> </li> <li> <p>Supports backpressure, a critical feature for handling the flow of data in a robust and efficient manner.</p> </li> </ul>"},{"location":"java/Concurrency%20-%20Part%204/#final-thoughts","title":"Final Thoughts","text":"<p>With Project Reactor, you gain a powerful model for asynchronous concurrency that eliminates many pitfalls of traditional thread-based programming.</p> <p>It\u2019s not about replacing threads\u2014it\u2019s about thinking differently and shifting paradigms. Let the system manage the \u201chow,\u201d while you focus on the \u201cwhat.\u201d</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/Concurrency%20-%20Part%205/","title":"Concurrency - Part 5","text":"<p>Before virtual threads, if you wanted to write scalable concurrent code without blocking physical OS threads, you typically chose one of these approaches:</p> <ul> <li>CompletableFuture \u2014 for async, non-blocking computation using futures and chaining.</li> <li>ExecutorService with thread pools \u2014 for managing a fixed number of threads efficiently.</li> <li>Reactive frameworks like Reactor or RxJava \u2014 for highly scalable, event-driven applications with non-blocking flows.</li> </ul> <p>Each of these had its own learning curve and trade-offs. In Java 21 (this PR), virtual threads changed the game by allowing:</p> <ul> <li>Blocking code (like <code>Thread.sleep()</code> or <code>InputStream.read()</code>)</li> <li>Written in a straightforward, linear style</li> <li>While still scaling to thousands of threads (because they're lightweight)</li> </ul>"},{"location":"java/Concurrency%20-%20Part%205/#clean-readable-code","title":"Clean, Readable Code","text":"<p>Virtual threads let you write code in a familiar, blocking style \u2014 without managing callbacks or chaining. Less boilerplate. More clarity.</p> <pre><code>// With CompletableFuture\nCompletableFuture.supplyAsync(() -&gt; getData())\n                 .thenApply(data -&gt; processData(data))\n                 .thenAccept(System.out::println);\n\n// With Virtual Threads\nvar result = getData();\nvar processed = processData(result);\nSystem.out.println(processed);\n</code></pre>"},{"location":"java/Concurrency%20-%20Part%205/#parallel-with-nodejs-asyncawait","title":"Parallel with Node.js Async/Await","text":"<p>If you\u2019re coming from a Node.js background, virtual threads in Java will feel similar to async/await \u2014 both enable writing asynchronous code that looks synchronous.</p> <p>Node.js with async/await:</p> <pre><code>const data = await getData();\nconst result = process(data);\n</code></pre> <p>Before async/await:</p> <pre><code>getData((data) =&gt; {\n    process(data, (result) =&gt; {\n        console.log(result);\n    });\n});\n</code></pre> <p>Just like async/await replaced callback hell in JavaScript, virtual threads eliminate the need for deeply nested <code>CompletableFuture</code> chains in Java. You retain the readability of sequential code, while the underlying runtime handles scheduling, blocking, and continuation behind the scenes.</p> <p>\u26a0\ufe0f Note: Virtual threads do real blocking, but very efficiently using JVM scheduling. <code>async/await</code>, on the other hand, is syntactic sugar over non-blocking Promises. The underlying model is different even if the surface syntax looks similar.</p>"},{"location":"java/Concurrency%20-%20Part%205/#better-resource-management","title":"Better Resource Management","text":"<ul> <li>Virtual threads are lightweight and managed by the JVM \u2014 you can create millions of them.</li> <li><code>CompletableFuture</code> relies on a fixed thread pool, which can become a bottleneck under heavy load.</li> </ul>"},{"location":"java/Concurrency%20-%20Part%205/#jvm-level-behavior-of-virtual-threads","title":"JVM-Level Behavior of Virtual Threads","text":"<p>Unlike platform threads (which are heavyweight OS threads), virtual threads are scheduled by the JVM, not the OS. This enables a large number of virtual threads (up to a million) to coexist.</p> <ul> <li>Platform Thread (PT): \\~0.25\u20131 MB of memory; JVM can manage \\~1,000\u201310,000</li> <li>Virtual Thread (VT): \\~1\u20132 KB of memory; JVM can manage up to 1 million</li> </ul> <p>Here\u2019s how the JVM handles virtual threads internally:</p> <ol> <li>A virtual thread runs on a platform thread (PT) until it hits a blocking operation (e.g., DB call, file I/O).</li> <li>When blocked, the JVM unmounts the virtual thread from the PT.</li> <li>The PT is now free to run another virtual thread.</li> <li>Once the result is ready, the virtual thread is remounted on an available PT and resumes execution.</li> </ol> <p>This mount/unmount mechanism ensures that the few available platform threads are always busy with active tasks, minimizing wasted resources.</p>"},{"location":"java/Concurrency%20-%20Part%205/#easier-debugging-and-tracing","title":"Easier Debugging and Tracing","text":"<p>With virtual threads, you get:</p> <ul> <li>Clean stack traces</li> <li>Compatibility with traditional debugging tools</li> <li>Easier step-through in IDEs</li> </ul> <p>As opposed to tracing through deeply chained async calls in <code>CompletableFuture</code>.</p>"},{"location":"java/Concurrency%20-%20Part%205/#quick-demo","title":"Quick Demo","text":"<pre><code>public class VirtualThreadExample {\n    public static void main(String[] args) throws InterruptedException {\n        Thread thread = Thread.ofVirtual()\n                .name(\"my-virtual-thread\")\n                .start(() -&gt;\n                        System.out.println(\"Running in: \" + Thread.currentThread().getName())\n                );\n\n        thread.join(); // Wait for the virtual thread to complete\n    }\n}\n\n//output\nRunning in: my-virtual-thread\n</code></pre>"},{"location":"java/Concurrency%20-%20Part%205/#virtual-threads-in-web-servers-spring-boot-tomcat","title":"Virtual Threads in Web Servers (Spring Boot / Tomcat)","text":"<p>Starting with Spring Boot 3.2+, you can enable virtual threads in embedded Tomcat using:</p> <pre><code>server.tomcat.virtual-threads.enabled=true\n</code></pre> <p>This allows your application to handle incoming web requests using virtual threads, greatly increasing concurrency without thread pool exhaustion.</p> <p>How it works:</p> <ol> <li>Tomcat accepts web requests and spawns virtual threads instead of blocking platform threads.</li> <li>These virtual threads call into your Spring-based business logic.</li> <li>Calls to storage (e.g., databases) can block without worrying about holding up platform threads.</li> <li>The JVM automatically manages scheduling behind the scenes.</li> </ol> <p>This design improves scalability \u2014 particularly for I/O-heavy workloads \u2014 without changing your controller or service code.</p> <p>\u26a0\ufe0f Note: While enabling virtual threads in Tomcat is powerful, it\u2019s worth proceeding cautiously \u2014 some libraries, tools, or native code may not yet fully support or benefit from the virtual thread model.</p>"},{"location":"java/Concurrency%20-%20Part%205/#final-thoughts","title":"Final Thoughts","text":"<p>Virtual threads are a major step forward in Java\u2019s concurrency model. They combine the simplicity of synchronous code with the scalability of asynchronous processing \u2014 all without the boilerplate and complexity of <code>CompletableFuture</code>.</p> <p>They\u2019re not a silver bullet, but for many applications, virtual threads are a cleaner, more powerful alternative.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/How%20HashMap%20Handles%20Collisions/","title":"How HashMap Handles Collisions","text":"<p>Collisions in a <code>HashMap</code> occur when multiple keys hash to the same bucket index. This situation arises because different keys can produce the same hash value. To handle such cases, <code>HashMap</code> employs separate chaining, where it stores multiple key-value pairs in a bucket using a linked list (or a balanced tree for performance optimization, starting from Java 8).</p> <p>Let\u2019s dive into an example to understand how this works.</p>"},{"location":"java/How%20HashMap%20Handles%20Collisions/#the-code-simulating-collisions","title":"The Code: Simulating Collisions","text":"<p>The following example demonstrates what happens when multiple keys in a <code>HashMap</code> collide due to having the same hash code:</p> <pre><code>import java.util.HashMap;\n\npublic class HashMapCollisionExample {\n    public static void main(String[] args) {\n\n       var map = new HashMap&lt;KeyWithSameHash, String&gt;();\n       map.put(new KeyWithSameHash(\"Key1\"), \"Value1\");\n       map.put(new KeyWithSameHash(\"Key2\"), \"Value2\");\n       map.put(new KeyWithSameHash(\"Key3\"), \"Value3\");\n\n       // prints Value3\n       System.out.println(map.get(new KeyWithSameHash(\"Key3\")));\n    }\n}\n\nclass KeyWithSameHash {\n    private String key;\n\n    public KeyWithSameHash(String key) {\n        this.key = key;\n    }\n\n    @Override\n    public int hashCode() {\n        return 1001; // Causes all keys to hash to the same bucket\n    }\n\n    @Override\n    public boolean equals(Object obj) {\n        if (this == obj) return true;\n        if (obj == null || getClass() != obj.getClass()) return false;\n        KeyWithSameHash other = (KeyWithSameHash) obj;\n        return key.equals(other.key);\n    }\n\n    @Override\n    public String toString() {\n        return key;\n    }\n}\n</code></pre>"},{"location":"java/How%20HashMap%20Handles%20Collisions/#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":"<ol> <li> <p>Hash Code Calculation    When you call <code>map.put(new KeyWithSameHash(\"Key3\"), \"Value3\")</code>, the <code>hashCode()</code> method of the key returns <code>1001</code> for all instances, forcing all keys to map to the same bucket.</p> </li> <li> <p>Bucket Index Determination    Although the hash code is <code>1001</code>, the bucket index is calculated using a bitwise operation (<code>hashCode % bucketArrayLength</code>), ensuring entries are distributed across available buckets. However, in this case, all keys land in the same bucket because their hash codes are identical.</p> </li> <li> <p>Collision Handling    Since multiple keys are mapped to the same bucket, <code>HashMap</code> handles the collision using a linked list (or balanced tree). Each entry in the bucket is stored as a node in the list.</p> </li> <li> <p>Key Lookup    When you retrieve a value using a key (e.g., <code>new KeyWithSameHash(\"Key3\")</code>), the <code>HashMap</code>:</p> <ul> <li>Finds the bucket for the key.</li> <li>Traverses the linked list in that bucket.</li> <li>Compares each key in the list using the <code>equals()</code> method until it finds a match.</li> </ul> </li> <li> <p>Value Retrieval    Once the key is located (where <code>equals()</code> returns <code>true</code>), the corresponding value is returned.</p> </li> </ol>"},{"location":"java/How%20HashMap%20Handles%20Collisions/#retrieval-complexity","title":"Retrieval Complexity","text":"<p>Despite all keys having the same hash code, the <code>HashMap</code> successfully retrieves the correct value due to its <code>equals()</code> comparison mechanism. However, retrieval complexity can degrade to (O(n)) if all keys hash to the same bucket and the bucket uses a linked list, or to (O(log n)) if the bucket uses a balanced tree (introduced in Java 8).</p>"},{"location":"java/How%20HashMap%20Handles%20Collisions/#wrap-up","title":"Wrap Up","text":"<ol> <li>Efficient Collision Handling: <code>HashMap</code> can handle collisions gracefully using separate chaining, ensuring reliable behavior even when hash codes collide.</li> <li>Importance of Proper <code>hashCode</code> Implementation: A poor hash code implementation, as shown in this example, can lead to performance degradation since all keys fall into the same bucket.</li> <li>Balanced Trees for Performance: Starting with Java 8, <code>HashMap</code> replaces the linked list with a balanced tree when collisions exceed a threshold, improving lookup times in heavily collided buckets.</li> </ol> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/","title":"How Threads Share Code in Java","text":"<p>In a previous post we explored how Spring Boot handles multiple requests using thread pools,  and how singleton-scoped components (like controllers and services) work in such an environment. But an equally important question remains: \u201cIf all threads share the same singleton, do they each copy the code into their stack?\u201d</p>"},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/#short-answer","title":"Short Answer","text":"<p>No, each thread does not copy the code of the singleton class into its own stack.</p> <p>Instead:</p> <ul> <li>The code is shared</li> <li>Each thread gets its own stack frame and local variables when invoking a method</li> </ul>"},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/#how-code-and-threads-work-in-java","title":"How Code and Threads Work in Java","text":""},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/#what-is-the-stack","title":"What Is the Stack?","text":"<p>Each thread in Java has its own call stack. It stores:</p> <ul> <li>Method call frames</li> <li>Local variables</li> <li>Return addresses</li> </ul> <p>Each time a method is called, a new stack frame is pushed onto the thread\u2019s private stack memory.</p>"},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/#where-does-the-code-live","title":"Where Does the Code Live?","text":"<p>The compiled method code (bytecode) lives in the JVM's method area, also known as:</p> <ul> <li>Metaspace (in modern JVMs)</li> <li>Code cache</li> </ul> <p>This area is shared by all threads. There's only one copy of the method, no matter how many threads invoke it.</p>"},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/#what-happens-when-multiple-threads-use-a-singleton","title":"What Happens When Multiple Threads Use a Singleton?","text":"<p>Consider this singleton class:</p> <pre><code>public class MySingleton {\n    private static final MySingleton instance = new MySingleton();\n\n    private MySingleton() {}\n\n    public static MySingleton getInstance() {\n        return instance;\n    }\n\n    public void doSomething() {\n        // some logic\n    }\n}\n</code></pre> <p>Now multiple threads run:</p> <pre><code>MySingleton.getInstance().doSomething();\n</code></pre> <p>Each thread:</p> <ul> <li>Calls <code>getInstance()</code> and receives the same singleton instance</li> <li> <p>Invokes <code>doSomething()</code>, which:</p> <ul> <li>Pushes a stack frame onto that thread\u2019s stack</li> <li>Allocates method-local variables</li> <li>Executes the shared code independently</li> </ul> </li> </ul> <p>The code for <code>doSomething()</code> is not copied \u2014 it is shared, but executed in separate thread contexts.</p>"},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/#why-singleton-components-are-safe-in-spring-if-stateless","title":"Why Singleton Components Are Safe in Spring \u2014 If Stateless","text":"<p>Spring Boot creates most beans as singletons by default:</p> <ul> <li>One instance per application context</li> <li>Shared across all requests and threads</li> </ul> <p>This is safe only if the bean is stateless.</p>"},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/#avoid-shared-mutable-state","title":"\u26a0\ufe0f Avoid Shared Mutable State","text":"<p>Here\u2019s a dangerous anti-pattern:</p> <pre><code>@Service\npublic class DangerousService {\n    private List&lt;String&gt; names = new ArrayList&lt;&gt;(); // \u274c shared mutable state!\n}\n</code></pre> <p>This <code>names</code> list is shared by all threads. Concurrent access can lead to:</p> <ul> <li>Race conditions</li> <li><code>ConcurrentModificationException</code></li> <li>Corrupted data</li> </ul>"},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/#use-method-local-variables-instead","title":"\u2705 Use Method-Local Variables Instead","text":"<p>Here\u2019s a safer version:</p> <pre><code>@Service\npublic class SafeService {\n    public void handleRequest(String name) {\n        List&lt;String&gt; names = new ArrayList&lt;&gt;(); // \u2705 local to this method\n        names.add(name);\n        // process names...\n    }\n}\n</code></pre> <p>Every request gets its own list, allocated in that thread\u2019s stack frame. No interference, no bugs.</p>"},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/#real-world-analogy-shared-code-private-data","title":"Real-World Analogy: Shared Code, Private Data","text":"<p>Imagine the method as a set of instructions written on a whiteboard in a room. Each thread walks into the room,  reads the instructions, and follows them using its own notebook (stack frame). Everyone reads the same board, but works with their own materials.</p>"},{"location":"java/How%20Threads%20Share%20Code%20in%20Java/#wrap-up","title":"Wrap-Up","text":"<p>Threads don\u2019t copy code \u2014 they just execute shared code in their own private space. That\u2019s why singleton beans in Spring are safe, as long as you keep them stateless.</p> <p>If your method uses only local variables and doesn\u2019t touch shared state, you're good.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/Java%20Generics%20as%20a%20Compile-Time%20Gift%20With%20a%20Runtime%20Disguise/","title":"Java Generics as a Compile-Time Gift With a Runtime Disguise","text":"<p>As someone who's been around Java long enough to remember writing raw <code>List</code> and <code>Map</code> code in Java 1.4, I often remind junior developers that generics weren't added to Java just for nicer-looking syntax. They were introduced to solve real problems \u2014 but with very real trade-offs. If you're writing Java today and treating generics like magic, you might be missing their original purpose \u2014 and their limitations.</p>"},{"location":"java/Java%20Generics%20as%20a%20Compile-Time%20Gift%20With%20a%20Runtime%20Disguise/#life-before-generics","title":"Life Before Generics","text":"<p>Before Java 5, using collections meant leaning on <code>Object</code> and casting manually:</p> <pre><code>List names = new ArrayList();\nnames.add(\"Alice\");\nnames.add(42); // No error here!\n\nString name = (String) names.get(1); // \ud83d\udca5 ClassCastException\n</code></pre> <p>The compiler didn\u2019t care what you added to the list \u2014 but your runtime certainly did. This kind of bug was common and painful.</p>"},{"location":"java/Java%20Generics%20as%20a%20Compile-Time%20Gift%20With%20a%20Runtime%20Disguise/#generics-gave-us-compile-time-safety","title":"Generics Gave Us Compile-Time Safety","text":"<p>Generics were introduced in Java 5 to let us declare intent and get compile-time protection:</p> <pre><code>List&lt;String&gt; names = new ArrayList&lt;&gt;();\nnames.add(\"Alice\");\n// names.add(42);  // \u274c Compile-time error\n</code></pre> <p>This reduces errors, clarifies intent, and works beautifully with modern IDEs for auto-completion and static analysis.</p>"},{"location":"java/Java%20Generics%20as%20a%20Compile-Time%20Gift%20With%20a%20Runtime%20Disguise/#but-dont-be-fooled-generics-are-erased","title":"But Don\u2019t Be Fooled \u2014 Generics Are Erased","text":"<p>Here\u2019s where the illusion ends: at runtime, Java doesn\u2019t remember any of those types. Due to type erasure, the JVM sees:</p> <pre><code>List&lt;String&gt; \u2192 just List\nMap&lt;String, Integer&gt; \u2192 just Map\n</code></pre> <p>So while this compiles:</p> <pre><code>List&lt;String&gt; list = new ArrayList&lt;&gt;();\naddUnsafe(list); // Adds Integer to List&lt;String&gt;\n\nfor (String s : list) {\n    System.out.println(s.length());  // \ud83d\udca5 ClassCastException\n}\n</code></pre> <p>The method <code>addUnsafe(List list)</code> can silently violate the contract:</p> <pre><code>void addUnsafe(List list) {\n    list.add(123); // No compiler warning \u2014 and no runtime type check\n}\n</code></pre> <p>The runtime won't protect you. The JVM has no clue that your list was intended to hold <code>String</code>s.</p>"},{"location":"java/Java%20Generics%20as%20a%20Compile-Time%20Gift%20With%20a%20Runtime%20Disguise/#false-sense-of-security-with-casts","title":"False Sense of Security with Casts","text":"<p>This leads to something I call \"false safety\" \u2014 you might write code like:</p> <pre><code>Join&lt;Case, User&gt; userJoin = (Join&lt;Case, User&gt;) someJoin;\n</code></pre> <p>and feel reassured that you've enforced type safety. But in reality, this cast won't be checked at runtime. If <code>someJoin</code> is not really a <code>Join&lt;Case, User&gt;</code>, the cast won\u2019t fail \u2014 because the generic info is gone. It gives the illusion of safety but offers none beyond compile-time.</p> <p>That's why in frameworks like JPA Criteria API, it's often more honest (and safer) to use:</p> <pre><code>Join&lt;?, ?&gt; userJoin = ...;\n</code></pre> <p>unless you truly need to depend on the exact type parameters.</p>"},{"location":"java/Java%20Generics%20as%20a%20Compile-Time%20Gift%20With%20a%20Runtime%20Disguise/#ides-the-real-mvp-here","title":"IDEs: The Real MVP Here","text":"<p>Generics wouldn\u2019t be nearly as helpful without IDEs supporting them so well.</p> <p>Modern IDEs like IntelliJ IDEA and Eclipse leverage generic metadata (stored in the <code>.class</code> files) to provide:</p> <ul> <li>Smart code suggestions</li> <li>Type mismatch warnings</li> <li>Code inspections</li> <li>Generics-aware refactorings</li> </ul> <p>If you compile this code:</p> <pre><code>var employees = new ArrayList&lt;Person&gt;();\nemployees.add(new Person(1L, \"admin\"));\n</code></pre> <p>and later open the <code>.class</code> file in IntelliJ, you might see something like this: (IntelliJ uses FernFlower to decompile)</p> <pre><code>ArrayList&lt;Person&gt; employees = new ArrayList();\nemployees.add(new Person(1L, \"admin\"));\n</code></pre> <p>This might be surprising at first \u2014 didn\u2019t we explicitly write <code>new ArrayList&lt;Person&gt;()</code>?</p> <p>Here\u2019s what\u2019s happening:</p> <ul> <li> <p>On the left-hand side, IntelliJ still shows <code>ArrayList&lt;Person&gt;</code> because generic type information is preserved in the class file as metadata. This metadata is accessible to IDEs, compilers, and reflection tools for purposes like static analysis and autocompletion. The decompiler cleverly reconstructs the original source by reading metadata like the <code>Signature</code> attribute from the <code>.class</code> file.</p> </li> <li> <p>On the right-hand side, however, the type argument (<code>&lt;Person&gt;</code>) is erased. This is because the JVM doesn\u2019t retain or use generic information at runtime. While that metadata enables your IDE to \"remember\" generic types, it plays no role in how the JVM executes your code.</p> </li> </ul> <p>Here\u2019s the key point: the JVM doesn\u2019t use that generic information at all. At runtime, it sees just <code>List</code> and <code>ArrayList</code>, with no awareness of <code>&lt;Person&gt;</code> \u2014 making generics a purely compile-time feature that relies heavily on IDEs and tooling to remain helpful.</p>"},{"location":"java/Java%20Generics%20as%20a%20Compile-Time%20Gift%20With%20a%20Runtime%20Disguise/#key-takeaways","title":"Key Takeaways","text":"<p>Generics in Java are one of those features that help you at compile time and make your code clearer and safer \u2014 but they don\u2019t offer any guarantees at runtime. Understanding that is key to writing robust code.</p> <p>Remember:</p> <ul> <li> <p>Don't rely on generics to enforce safety at runtime.</p> </li> <li> <p>Avoid unnecessary type casts that give you a false sense of safety.</p> </li> <li> <p>Use IDEs and static analysis tools to your advantage.</p> </li> <li> <p>Respect type erasure \u2014 it\u2019s silently watching your back... and sometimes letting you fall.</p> </li> </ul> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/Java%E2%80%99s%20Mission%20-%20No%20More%20Excuses/","title":"Java\u2019s Mission, No More Excuses","text":"<p>Java isn't trying to be the flashiest language or lead every trend \u2014 it\u2019s focused on one strategic goal: removing every valid excuse not to use it.</p>"},{"location":"java/Java%E2%80%99s%20Mission%20-%20No%20More%20Excuses/#how-java-identifies-what-to-improve","title":"How Java Identifies What to Improve","text":"<p>The evolution of Java isn\u2019t random \u2014 it\u2019s deeply intentional. The OpenJDK community continuously monitors:</p> <ul> <li>Pain points reported by developers \u2014 via mailing lists, JEP discussions, and community channels like StackOverflow or GitHub.</li> <li>What competing languages are doing better \u2014 by analyzing language adoption trends, performance benchmarks, and use cases where Java is not the first choice.</li> <li>Shifts in architecture and deployment \u2014 such as the rise of microservices, serverless, and native images.</li> </ul> <p>Once gaps are identified, Java doesn\u2019t rush to imitate \u2014 instead, it focuses on incorporating solutions in a way that aligns with the language\u2019s long-term principles: stability, backward compatibility, and performance.</p> <p>The OpenJDK community regularly highlights active projects that reflect this improvement process in action. Let\u2019s look at the top three:</p>"},{"location":"java/Java%E2%80%99s%20Mission%20-%20No%20More%20Excuses/#1-project-loom-lightweight-concurrency","title":"1. Project Loom \u2013 Lightweight Concurrency","text":"<p>Concurrency has always been a pain point in Java, especially for highly parallel workloads. Developers would often turn to Go or Elixir for lightweight threading models. Loom addresses this by introducing virtual threads that scale massively without the overhead of traditional Java threads.</p> <p>Excuse removed: \u201cJava threads don\u2019t scale.\u201d</p>"},{"location":"java/Java%E2%80%99s%20Mission%20-%20No%20More%20Excuses/#2-project-zgc-sub-millisecond-gc-pauses","title":"2. Project ZGC \u2013 Sub-Millisecond GC Pauses","text":"<p>Real-time systems need predictable latency, and garbage collection (GC) used to be Java\u2019s bottleneck. Competing systems in C or Rust offered manual memory management for tighter control. ZGC turns the tables with pause times under 1 millisecond, even on large heaps.</p> <p>Excuse removed: \u201cGC pauses make Java unsuitable for low-latency apps.\u201d</p>"},{"location":"java/Java%E2%80%99s%20Mission%20-%20No%20More%20Excuses/#3-project-leyden-faster-startup-and-warmup","title":"3. Project Leyden \u2013 Faster Startup and Warmup","text":"<p>In cloud-native and serverless worlds, startup time matters. Languages like Go compile to native binaries that start instantly, while Java traditionally requires a JVM warmup. Leyden brings ahead-of-time compilation and class data sharing improvements to close this gap.</p> <p>Excuse removed: \u201cJava starts too slowly.\u201d</p>"},{"location":"java/Java%E2%80%99s%20Mission%20-%20No%20More%20Excuses/#the-bigger-picture","title":"The Bigger Picture","text":"<p>Java doesn\u2019t need to reinvent itself to stay relevant \u2014 it needs to keep evolving with purpose. These projects show how Java carefully studies developer needs, learns from its competition, and delivers changes that remove blockers without sacrificing its core strengths.</p> <p>No, Java doesn\u2019t want to be best at everything.</p> <p>But it absolutely wants to remove every excuse not to use it.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/","title":"Mock vs Spy in Mockito \u2014 Never Ask Again","text":"<p>When writing unit tests in Java using Mockito, a common question pops up:</p> <p>\u201cShould I use <code>@Mock</code> or <code>@Spy</code>?\u201d</p> <p>If you\u2019ve asked that before, this guide will make sure you never forget the answer again.</p>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#the-core-idea","title":"The Core Idea","text":"<p>When you're testing a class in isolation:</p> <ul> <li>Use <code>@Mock</code> for dependencies (like repositories, clients, etc.).</li> <li>Use <code>@InjectMocks</code> to inject those mocks into the class under test.</li> <li>Use <code>@Spy</code> when you want to call real methods, but override some behavior in the same class. Think of it as partial mocking.</li> </ul>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#the-memory-trick","title":"The Memory Trick","text":"<p>Mock = Mannequin\\ Spy = Secret Agent</p> <ul> <li>A mock is like a mannequin \u2014 lifeless and fake, does exactly what you script it to.</li> <li>A spy is like a secret agent \u2014 it behaves like the real thing, but you can feed it secret instructions when needed.</li> </ul> <p>With a <code>@Spy</code>, you get the real object but with override powers.</p>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#example-mock-injectmocks","title":"Example: <code>@Mock</code> + <code>@InjectMocks</code>","text":""},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#service-to-be-tested","title":"Service to be tested","text":"<pre><code>@Service\npublic class UserService {\n    private final UserRepository userRepository;\n\n    public UserService(UserRepository userRepository) {\n        this.userRepository = userRepository;\n    }\n\n    public User getUserById(Long id) {\n        return userRepository.findById(id)\n                .orElseThrow(() -&gt; new RuntimeException(\"User not found\"));\n    }\n}\n</code></pre>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#unit-test","title":"Unit test","text":"<p>You're testing a <code>UserService</code> that depends on a <code>UserRepository</code>:</p> <pre><code>@ExtendWith(MockitoExtension.class)\nclass UserServiceTest {\n\n    @Mock\n    private UserRepository userRepository;\n\n    @InjectMocks\n    private UserService userService; // real service, with mocked repository injected\n\n    @Test\n    void testGetUser() {\n        Mockito.when(userRepository.findById(1L)).thenReturn(Optional.of(new User(\"John\")));\n        assertEquals(\"John\", userService.getUserById(1L).getName());\n    }\n}\n</code></pre> <p>Use this when your service calls external dependencies and you want full control over them.</p>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#example-spy-to-override-part-of-the-class","title":"Example: <code>@Spy</code> to Override Part of the Class","text":"<p>Let\u2019s say your service looks like this:</p> <pre><code>@Service\npublic class NotificationService {\n\n    public String getMessageType(String userType) {\n        // complex logic here\n        return userType.equals(\"admin\") ? \"PRIORITY\" : \"STANDARD\";\n    }\n\n    public String sendMessage(String userType, String message) {\n        String type = getMessageType(userType);\n        return \"Sent \" + type + \" message: \" + message;\n    }\n}\n</code></pre>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#unit-test_1","title":"Unit test","text":"<pre><code>@ExtendWith(MockitoExtension.class)\nclass NotificationServiceTest {\n\n    @Spy\n    private NotificationService notificationService;\n\n    @Test\n    void testSendMessage_withStubbedGetMessageType() {\n        Mockito.doReturn(\"OVERRIDE\").when(notificationService).getMessageType(\"guest\");\n\n        String result = notificationService.sendMessage(\"guest\", \"Hello!\");\n        Assertions.assertEquals(\"Sent OVERRIDE message: Hello!\", result);\n    }\n}\n</code></pre> <p>Use <code>@Spy</code> when you're testing real logic, but want to override specific method calls.</p>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#spy-injectmocks-use-with-caution","title":"Spy + InjectMocks: Use With Caution","text":"<p>What if you want to mock a dependency (like a repository) and also stub a method in your service?</p> <p>Technically, you can use <code>@Spy @InjectMocks</code> together:</p> <pre><code>@Spy\n@InjectMocks\nprivate MyService myService;\n</code></pre> <p>But this isn't always reliable \u2014 especially when constructor injection is involved.</p>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#safer-approach-manual-injection","title":"Safer Approach: Manual Injection","text":"<pre><code>@ExtendWith(MockitoExtension.class)\nclass MyServiceTest {\n\n    @Mock\n    private MyRepository myRepository;\n\n    @Spy\n    private MyService myService = new MyService(myRepository);\n\n    @Test\n    void testSomething() {\n        Mockito.doReturn(\"stubbed\").when(myService).someInternalMethod();\n        Mockito.when(myRepository.findSomething()).thenReturn(\"mocked result\");\n\n        String result = myService.mainMethod();\n        Assertions.assertEquals(\"expected result\", result);\n    }\n}\n</code></pre> <p>Or, fully manual with no annotations:</p> <pre><code>@Test\nvoid testWithManualSpy() {\n    MyRepository mockRepo = Mockito.mock(MyRepository.class);\n    MyService spyService = Mockito.spy(new MyService(mockRepo));\n\n    Mockito.when(mockRepo.findSomething()).thenReturn(\"mocked\");\n    Mockito.doReturn(\"stubbedInternal\").when(spyService).someInternalMethod();\n\n    String result = spyService.mainMethod();\n    Assertions.assertEquals(\"expected result\", result);\n}\n</code></pre> <p>This approach gives you full control and avoids surprises from framework behavior.</p>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#bonus-mock-vs-mockbean","title":"Bonus: <code>@Mock</code> vs <code>@MockBean</code>","text":"<p>You might have also seen <code>@MockBean</code> in Spring Boot tests \u2014 here's how it differs from <code>@Mock</code>.</p> Annotation Used In Replaces Spring Bean? Spring Context Required <code>@Mock</code> Unit tests \u274c No \u274c No <code>@MockBean</code> Integration tests (<code>@SpringBootTest</code>, <code>@WebMvcTest</code>, etc.) \u2705 Yes \u2705 Yes <ul> <li>Use <code>@Mock</code> when you're testing in isolation, like with <code>@ExtendWith(MockitoExtension.class)</code>.</li> <li>Use <code>@MockBean</code> when you want to boot up a Spring context and replace a real bean (like a repository or service) with a mock.</li> </ul>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#example-of-mockbean","title":"Example of <code>@MockBean</code>:","text":"<pre><code>@SpringBootTest\nclass UserControllerIntegrationTest {\n\n    @MockBean\n    private UserRepository userRepository; // replaces actual bean in Spring context\n\n    @Autowired\n    private UserService userService;\n\n    // Test logic using real service but mocked repository\n}\n</code></pre> <p>This is great for higher-level tests where you want Spring wiring + selective mocking.</p>"},{"location":"java/Mock%20vs%20Spy%20in%20Mockito%20%E2%80%94%20Never%20Ask%20Again/#recap","title":"Recap","text":"<ul> <li><code>@Mock</code>: Use for dependencies. It\u2019s like a mannequin.</li> <li><code>@Spy</code>: Use for real objects when you want to override specific methods. Like a secret agent.</li> <li><code>@InjectMocks</code>: Injects your mocks or spies into the class under test.</li> <li><code>@MockBean</code>: Use in Spring Boot integration tests to replace real Spring beans with mocks in the application context.</li> <li>Always use <code>@ExtendWith(MockitoExtension.class)</code> when using Mockito with JUnit 5.</li> </ul> <p>Just remember:</p> <p>Mocks are mannequins. Spies are secret agents.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/","title":"Stay Friends with the Console","text":"<p>As developers, we often choose tools that enhance productivity and streamline our workflows. For Java developers, IntelliJ IDEA and Visual Studio Code (VS Code) are two popular choices. Each brings unique strengths to the table\u2014IntelliJ's rich UI simplifies complex setups, while VS Code's explicit configurations encourage familiarity with command-line operations.</p> <p>But here's a critical observation: developers using IntelliJ often become less familiar with the actual commands their tools execute behind the scenes. This post argues why staying \"friends with the console\" is vital, even if you rely on an IDE with advanced features.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#the-abstraction-gap","title":"The Abstraction Gap","text":"<p>When you run a project in IntelliJ IDEA, the process feels seamless: - Select a run configuration. - Click the green play button. - Watch your application start.</p> <p>Behind the scenes, IntelliJ generates a command to launch your application, passing JVM arguments, system properties, and classpath settings. However, many developers don\u2019t inspect this command, creating a knowledge gap. Over time, this reliance on the UI can lead to an aversion to using the console.</p> <p>In contrast, VS Code's <code>launch.json</code> file makes you explicitly define every aspect of your run configuration: - The main class to launch. - The JVM arguments to include. - Environment variables and debugging options.</p> <p>This approach forces you to understand the command being executed, fostering a deeper awareness of what\u2019s happening under the hood.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#why-it-matters","title":"Why It Matters","text":""},{"location":"java/Stay%20Friends%20with%20the%20Console/#1-portability","title":"1. Portability","text":"<p>Knowing the command being executed allows you to replicate the same setup outside your IDE. This is especially critical in environments like CI/CD pipelines, where everything runs on the command line.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#2-debugging-skills","title":"2. Debugging Skills","text":"<p>When something breaks in production, you won\u2019t have IntelliJ\u2019s UI to save you. Understanding how to craft and troubleshoot the equivalent command-line invocation ensures you're better equipped to diagnose and resolve issues.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#3-tool-independence","title":"3. Tool Independence","text":"<p>Becoming overly reliant on an IDE can tie your productivity to that tool. By understanding the underlying commands, you\u2019re not just an IntelliJ user; you\u2019re a developer who can adapt to any environment.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#bridging-the-gap","title":"Bridging the Gap","text":""},{"location":"java/Stay%20Friends%20with%20the%20Console/#1-inspect-run-configurations","title":"1. Inspect Run Configurations:","text":"<p>Every time you run your application, IntelliJ logs the generated command in the Run or Debug console. Take a moment to review it. Understand the JVM arguments, the classpath, and any system properties being passed.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#2-experiment-with-the-command-line","title":"2. Experiment with the Command Line:","text":"<p>Copy the command from IntelliJ\u2019s logs and execute it directly in your terminal. Modify parameters, try different options, and see how your application behaves.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#3-translate-ui-to-commands","title":"3. Translate UI to Commands:","text":"<p>When setting up run configurations in IntelliJ, think about how you\u2019d define the same setup in a tool like VS Code or Maven. This mental exercise helps solidify your understanding.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#4-leverage-tools-like-maven-and-gradle","title":"4. Leverage Tools Like Maven and Gradle:","text":"<p>These tools are designed for command-line execution and often integrate seamlessly with IDEs. Practice running your application with commands like the following:</p> <p>Command Generated by IntelliJ:    <pre><code>/Users/youruser/.sdkman/candidates/java/21.0.1-amzn/bin/java \\\n-Dspring.output.ansi.enabled=always \\\n-Dfile.encoding=UTF-8 \\\n-classpath /Users/youruser/project/target/classes:/Users/youruser/.m2/repository/org/springframework/... \\\ncom.example.Application\n</code></pre></p> <p>Equivalent Maven Command:    <pre><code>mvn spring-boot:run \\\n-Dspring-boot.run.jvmArguments=\"-Dspring.output.ansi.enabled=always -Dfile.encoding=UTF-8\"\n</code></pre></p> <ul> <li>IntelliJ: Handles the classpath and configuration automatically but abstracts the process.</li> <li>Maven: Provides a clear and portable way to replicate the same execution, ensuring you stay familiar with the underlying mechanics.</li> </ul>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#embrace-the-best-of-both-worlds","title":"Embrace the Best of Both Worlds","text":"<p>Using IntelliJ IDEA doesn\u2019t mean abandoning the console. Instead, think of the IDE as a tool that enhances your productivity without replacing foundational knowledge. When you understand the commands your IDE generates, you unlock a new level of control over your development process.</p> <p>Whether you\u2019re configuring a debugging session, tweaking JVM options, or deploying your application to production, staying friends with the console ensures you remain on top of your craft.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#final-thought","title":"Final Thought","text":"<p>An IDE should simplify your workflow, not shield you from understanding it. So, the next time you click \"Run\" in IntelliJ, take a moment to explore the command it generates. It\u2019s not just a helpful exercise\u2014it\u2019s a step toward becoming a more confident and capable developer.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"security/Defending%20Against%20XSS%20in%20React%20and%20JSP/","title":"Defending Against XSS in React and JSP","text":"<p>Cross-Site Scripting (XSS) is one of the most common and dangerous vulnerabilities in web applications. While modern  frontend frameworks like React provide strong built\u2011in protection, older technologies like JSP rely on manual escaping,  making it easier to introduce XSS bugs.</p> <p>In this post, we compare how JSP (as a legacy server-rendered frontend) and React (as modern client-side frontend)  handle XSS.</p>"},{"location":"security/Defending%20Against%20XSS%20in%20React%20and%20JSP/#react-xss-is-mostly-handled-if-you-let-it","title":"React: XSS Is Mostly Handled \u2014 If You Let It","text":""},{"location":"security/Defending%20Against%20XSS%20in%20React%20and%20JSP/#react-escapes-by-default","title":"React escapes by default","text":"<p>React\u2019s rendering engine automatically escapes all content interpolated into JSX. For example:</p> <pre><code>function App() {\n  const [input, setInput] = useState('');\n\n  return (\n    &lt;div&gt;\n      &lt;input value={input} onChange={e =&gt; setInput(e.target.value)} /&gt;\n      &lt;div&gt;{input}&lt;/div&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre> <p>If a user types:</p> <pre><code>&lt;img src=\"x\" onerror=\"alert('XSS')\" /&gt;\n</code></pre> <p>React will render it as text (no image loads, and no script runs).  This happens because React automatically replaces certain special HTML characters \u2014 like <code>&lt;</code>, <code>&gt;</code>, <code>&amp;</code>, and <code>\"</code> \u2014 with their safe HTML-escaped versions (<code>&amp;lt;</code>, <code>&amp;gt;</code>, <code>&amp;amp;</code>, <code>&amp;quot;</code>) before adding them to the page\u2019s DOM.</p>"},{"location":"security/Defending%20Against%20XSS%20in%20React%20and%20JSP/#you-can-skip-the-built-in-protection-by-using-dangerouslysetinnerhtml","title":"You can skip the built-in protection by using <code>dangerouslySetInnerHTML</code>","text":"<p>It reflects React\u2019s security-first design: by including the word \u201cdangerously\u201d, the framework signals clearly that you\u2019re bypassing its built-in protections and assuming responsibility for content safety. For example:</p> <pre><code>&lt;div dangerouslySetInnerHTML={{ __html: userInput }} /&gt;\n</code></pre> <p>If <code>userInput</code> contains <code>&lt;script&gt;alert('XSS')&lt;/script&gt;</code>, the script will run. If you choose to use <code>dangerouslySetInnerHTML</code>,  you take full responsibility for sanitizing the input \u2014 for example, by using a library like DOMPurify.</p> <pre><code>import DOMPurify from 'dompurify';\n\nfunction App() {\n  const [input, setInput] = useState('');\n  const clean = DOMPurify.sanitize(input);\n\n  return (\n    &lt;div&gt;\n      &lt;input value={input} onChange={e =&gt; setInput(e.target.value)} /&gt;\n      &lt;div dangerouslySetInnerHTML={{ __html: clean }} /&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre>"},{"location":"security/Defending%20Against%20XSS%20in%20React%20and%20JSP/#jsp-xss-prevention-is-manual-and-easy-to-get-wrong","title":"JSP: XSS Prevention Is Manual \u2014 and Easy to Get Wrong","text":"<p>JSP is a server-rendered frontend technology used in older Java-based applications. Unlike React, it does not escape output by default. If you print user input directly into HTML, it will be rendered as-is \u2014 including any malicious scripts.</p>"},{"location":"security/Defending%20Against%20XSS%20in%20React%20and%20JSP/#vulnerable-example","title":"Vulnerable example","text":"<pre><code>&lt;%= request.getParameter(\"username\") %&gt;\n</code></pre> <p>If <code>username</code> is <code>&lt;script&gt;alert('XSS')&lt;/script&gt;</code>, the script will run in the browser.</p>"},{"location":"security/Defending%20Against%20XSS%20in%20React%20and%20JSP/#the-safe-and-recommended-way","title":"The safe and recommended way","text":"<p>Use JSTL's <code>&lt;c:out&gt;</code> to escape user content:</p> <pre><code>&lt;%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %&gt;\n&lt;c:out value=\"${param.username}\" /&gt;\n</code></pre> <p>This safely escapes HTML characters like <code>&lt;</code>, <code>&gt;</code>, and <code>&amp;</code>.</p>"},{"location":"security/Defending%20Against%20XSS%20in%20React%20and%20JSP/#how-cout-compares-to-other-options","title":"How <code>&lt;c:out&gt;</code> compares to other options","text":"Technique Escapes HTML? Handles nulls? Recommended <code>${param.username}</code> \u274c \u274c \u274c <code>&lt;%= request.getParameter(...) %&gt;</code> \u274c \u274c \u274c <code>fn:escapeXml(...)</code> \u2705 \u274c \u26a0\ufe0f (okay) <code>&lt;c:out value=\"...\" /&gt;</code> \u2705 \u2705 \u2705"},{"location":"security/Defending%20Against%20XSS%20in%20React%20and%20JSP/#why-cout-is-used-even-for-non-user-data","title":"Why <code>&lt;c:out&gt;</code> is used even for non-user data","text":"<p>You might see <code>&lt;c:out&gt;</code> used consistently throughout JSP code \u2014 even when rendering values that aren\u2019t obviously user-driven. That\u2019s intentional:</p> <ol> <li>Defense-in-depth \u2014 a value that\u2019s safe today might come from user input tomorrow.</li> <li>Safe defaults \u2014 always escaping removes guesswork and reduces mistakes.</li> <li>Future-proofing \u2014 requirements change; code should be resilient.</li> <li>Consistency \u2014 uniform escaping makes templates easier to audit and maintain.</li> </ol>"},{"location":"security/Defending%20Against%20XSS%20in%20React%20and%20JSP/#enterprise-ready-tools-to-find-xss-in-legacy-jsp","title":"Enterprise-Ready Tools to Find XSS in Legacy JSP","text":"<p>Manually spotting XSS in large JSP codebases can be challenging, especially as projects grow and patterns become harder to track. This is where SonarQube (static application security testing, or SAST) helps \u2014 it analyzes source code to detect insecure patterns, such as unescaped <code>&lt;%= ... %&gt;</code> or unsanitized user input, and integrates into CI/CD pipelines to catch issues early. Burp Suite (dynamic application security testing, or DAST) complements this by scanning and probing a running application to uncover vulnerabilities that static analysis might miss. Using both static and dynamic testing together provides strong, complementary coverage when maintaining or auditing legacy frontend systems.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/","title":"Seamless AWS Access - Setting Up Azure AD as a Federated Identity Provider","text":"<p>Imagine you run a growing organization where employees need access to AWS services. Managing individual IAM users for each employee would be complex and inefficient. This is where identity federation becomes a game-changer. Instead of creating separate IAM users, you can configure Azure AD as an identity provider, allowing employees to log into AWS using their existing Azure AD credentials. This setup leverages SAML federation, ensuring seamless and secure access management without the overhead of IAM user administration.</p> <p>In this blog post, we'll explore identity federation, its key concepts, and how to set up Azure AD as an identity provider for AWS.</p>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#what-is-federation","title":"What is Federation?","text":"<p>Federation enables users to authenticate using their existing credentials from a trusted identity provider (IdP) rather than creating separate accounts for different applications. This allows multiple systems or organizations to establish trust, enabling Single Sign-On (SSO) and seamless access to resources across different platforms.</p>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#key-concepts-in-federation","title":"Key Concepts in Federation","text":""},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#federated-identity-saml-federation","title":"Federated Identity (SAML Federation)","text":"<ul> <li>Users authenticate via an external identity provider (IdP) instead of managing credentials separately for each application.</li> <li>For example, logging into a website using Google or Facebook credentials means the identity is federated.</li> <li>The identity provider verifies the user's credentials and shares user attributes (such as email and user ID) with the relying application.</li> </ul>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#delegated-authentication","title":"Delegated Authentication","text":"<ul> <li>Instead of handling authentication directly, an application (OAuth2 client) delegates the process to an external provider.</li> <li>Protocols like SAML and OpenID Connect (OIDC) are commonly used for this, depending on the use case.</li> <li>The OAuth2 authorization server trusts the identity provider to authenticate the user securely.</li> </ul>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#single-sign-on-sso","title":"Single Sign-On (SSO)","text":"<ul> <li>Federation allows SSO, meaning users authenticate once and can access multiple applications without needing to log in again.</li> <li>Example: Employees signing into corporate applications via Azure AD gain access to various services without repeated logins.</li> </ul>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#identity-providers-idps","title":"Identity Providers (IdPs)","text":"<ul> <li>Common identity providers used in a federated OAuth2 setup include:</li> <li>Google</li> <li>Facebook</li> <li>Azure AD</li> <li>Okta</li> <li>Any SAML or OpenID Connect compliant provider</li> <li>The SAML or OpenID Connect provider establishes a federation relationship with these IdPs, allowing authentication via external credentials.</li> </ul>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#configuring-azure-ad-as-an-identity-provider-for-aws","title":"Configuring Azure AD as an Identity Provider for AWS","text":"<p>Organizations often use Azure AD for authentication while running workloads on AWS. By integrating AWS IAM Identity Center (formerly AWS SSO) with Azure AD, users can log in to AWS resources using their Azure credentials.</p>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#steps-to-set-up-azure-ad-for-aws-access","title":"Steps to Set Up Azure AD for AWS Access","text":"<ol> <li>Configure IAM Roles for SAML Users</li> <li>In AWS IAM, create roles with permissions needed for users.</li> <li>Link the role with the identity provider by configuring the SAML trust relationship.</li> <li>Define role mappings in AWS IAM Identity Center, so users receive appropriate permissions upon logging in.</li> <li>AWS STS will issue temporary credentials for users based on their assigned role.</li> <li>Enable IAM Identity Center in AWS: Navigate to IAM Identity Center in the AWS console and select External Identity Provider.</li> <li>Register AWS in Azure AD: In the Azure Portal, add AWS as an enterprise application under Azure Active Directory.</li> <li>Configure SAML in Azure AD: Enable Single Sign-On (SSO) and set up SAML attributes.</li> <li>Integrate with AWS IAM Identity Center: Upload the Azure AD Metadata XML in AWS and configure user mappings.</li> <li>Assign Users and Groups: Ensure assigned users/groups match in both Azure AD and AWS IAM Identity Center.</li> <li>Test the Integration: Verify login via Azure AD and check role-based access.</li> </ol>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#saml-federation-flow","title":"SAML Federation Flow","text":"<ol> <li>User attempts to log in to an application.</li> <li>The application redirects the user to a SAML identity provider (e.g., Azure AD).</li> <li>The user authenticates with the identity provider.</li> <li>The identity provider returns a SAML assertion to AWS IAM Identity Center.</li> <li>AWS Security Token Service (STS) issues temporary security credentials based on the SAML assertion.</li> <li>The user assumes an IAM role in AWS, granting them appropriate permissions.</li> <li>The application uses these temporary credentials to grant access to AWS resources.</li> </ol>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#key-benefits","title":"Key Benefits","text":"<ul> <li>Centralized Access Management: Manage AWS permissions via Azure AD.</li> <li>Single Sign-On: Users authenticate once to access AWS services.</li> <li>Enhanced Security: Enforce Conditional Access Policies and MFA.</li> </ul> <p>With this setup, organizations can leverage Azure AD\u2019s security while ensuring streamlined access control in AWS.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"soft-skills/Invisible%20Ownership%20Subtasks/","title":"Invisible Ownership Subtasks","text":"<p>When software developers pick up a new ticket, they often see a list of clearly defined subtasks\u2014requirements documented in tools like Jira that need to be completed to move the ticket forward. However, the best developers recognize that visible subtasks are only part of the picture. There's another category, the \"invisible ownership subtasks,\" that distinguishes those who truly take ownership from those who just check the boxes.</p> <p>Invisible ownership subtasks are those that never make it into a ticket management system. They require thinking about the wider impact of the change\u2014how it affects other modules, edge cases, and dependencies. Developers with this mindset have a deeper sense of responsibility and seek to understand the consequences of their work.</p> <p>A developer with low ownership might complete all visible subtasks, mark the ticket as \"done,\" and move on. In contrast, developers with high ownership see each ticket as part of a larger system they are responsible for. They ask questions like:</p> <ul> <li>How does this change impact related modules?</li> <li>Are there any integration concerns?</li> <li>If this change is introducing a new dependency to some libraries, how will it get built in CI/CD?</li> <li>If this is a backend change, how is it going to affect database migrations and downstream reports?</li> <li>Are there any security implications related to this change?</li> <li>How will this impact performance under load?</li> <li>What are the testing requirements for these changes to ensure robustness?\"</li> </ul> <p>Basically, every ticket has the potential to give you deeper knowledge of how different subsystems and teams in your company work, if you keep your curiosity alive and thriving.</p> <p>These invisible subtasks reveal the depth of a developer's engagement and often make the difference between a patchy implementation and a robust solution. Managers can use this concept to assess their team's level of ownership. Developers who ask about broader implications and take proactive steps demonstrate greater ownership. They don't just close a ticket\u2014they ensure the change is successful in every dimension.</p> <p>Cultivating this kind of ownership requires a supportive environment. Managers need to create a culture where curiosity is encouraged, and developers feel empowered to take extra time to address invisible subtasks. Encouraging invisible ownership shifts teams from a culture of ticket-closing to one of high-quality, impactful development.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"soft-skills/Staying%20on%20Track%20When%20a%20Ticket%20Gets%20Complicated/","title":"Staying on Track When a Ticket Gets Complicated","text":"<p>You start working on a ticket thinking it\u2019ll be done in a day or two. But then\u2026 things get complicated. Something doesn\u2019t work. Docs aren\u2019t clear. You fix one thing, and two new problems show up.</p> <p>Don\u2019t worry \u2014 it happens to all of us. Here are some simple and helpful tips to keep moving when a ticket starts dragging on.</p>"},{"location":"soft-skills/Staying%20on%20Track%20When%20a%20Ticket%20Gets%20Complicated/#1-start-on-your-own-but-know-when-to-ask-for-help","title":"1. Start on Your Own \u2014 But Know When to Ask for Help","text":"<p>The first step is to try. Explore the codebase. Search your organization\u2019s repositories \u2014 maybe a similar problem has already been solved. Consult the framework or library documentation. Use AI tools for assistance.</p> <p>There\u2019s a point where continuing alone becomes counterproductive. Recognizing that point is a skill in itself. If you're hitting the same wall repeatedly, it's time to reach out \u2014 whether it\u2019s to a teammate, another team, or someone who has context on the problem.</p> <p>Asking for help isn\u2019t a weakness \u2014 it\u2019s a way to unlock progress.</p>"},{"location":"soft-skills/Staying%20on%20Track%20When%20a%20Ticket%20Gets%20Complicated/#2-split-the-work-essential-vs-optional","title":"2. Split the Work: Essential vs. Optional","text":"<p>Sometimes, the technical challenge lies in an optional part of the ticket \u2014 maybe a UI optimization, a secondary integration, or a refactor that seemed small at the beginning. Don\u2019t let that part hold the entire delivery hostage.</p> <p>Instead, break the ticket down:</p> <ul> <li>Finish the essential part.</li> <li>Document your current state on the challenging piece.</li> <li>Create a follow-up ticket.</li> <li>Move it to the backlog for later.</li> </ul> <p>This allows the team to make progress without losing sight of the long-term goal.</p>"},{"location":"soft-skills/Staying%20on%20Track%20When%20a%20Ticket%20Gets%20Complicated/#3-take-a-break-seriously","title":"3. Take a Break \u2014 Seriously","text":"<p>It sounds simple, but it\u2019s powerful.</p> <p>Call it a day. Sign off early if you\u2019re feeling overwhelmed and start fresh the next morning.  I\u2019ve lost count of how many times a challenge in the late evening showed its solution the next morning.</p> <p>Your brain sometimes just needs rest \u2014 not more effort.</p>"},{"location":"soft-skills/Staying%20on%20Track%20When%20a%20Ticket%20Gets%20Complicated/#4-communicate-early","title":"4. Communicate Early","text":"<p>If a ticket has been in progress for a while and it\u2019s starting to look risky for the sprint, don\u2019t wait for someone to ask \u2014 be proactive.</p> <p>In your pull request, acknowledge the limitations. Suggest reasonable improvements that can be done now, and propose follow-ups for the rest. When reviewers see that you\u2019ve thought about trade-offs and already scoped future work, they\u2019re more likely to be pragmatic \u2014 rather than push for perfection at the cost of timelines.</p> <p>Include a note like:</p> <p>\u201cThis implementation covers X and Y. Z requires more investigation and is tracked in ticket ABC-123. Happy to discuss if needed.\u201d</p> <p>Setting expectations helps your reviewers focus on what matters now.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/","title":"How Singleton Components Work with Thread Pools","text":"<p>Spring\u2019s component model is built on the principle of singletons for many of its core beans, ensuring efficiency and consistency across your application. If you\u2019ve ever wondered how Spring handles multiple requests while maintaining a single instance for components like controllers, services, and repositories, this article will walk you through it with practical examples and insights.</p> <ul> <li>Source code : Singleton Components Demo</li> </ul>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#what-are-singletons-in-spring","title":"What are Singletons in Spring?","text":"<p>In Spring, the default scope of beans is <code>singleton</code>, which means Spring creates exactly one instance of a bean per application context. This single instance is shared across all requests, ensuring consistency and reducing overhead.</p> <p>To verify that components like controllers, services, and repositories are singletons, you can use <code>System.identityHashCode</code> to print the unique memory reference hash for each bean instance.</p>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#verifying-singleton-behavior-with-code","title":"Verifying Singleton Behavior with Code","text":"<p>Let\u2019s take a look at a simple Spring Boot application to demonstrate this.</p>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#1-order-entity","title":"1. Order Entity","text":"<p>This entity represents a basic <code>Order</code> object stored in a database:</p> <pre><code>@Entity\n@Table(name = \"orders\")\n@Data\n@Builder\n@NoArgsConstructor\n@AllArgsConstructor\npublic class Order {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    private String name;\n    private String description;\n}\n</code></pre>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#2-order-controller","title":"2. Order Controller","text":"<p>The controller exposes an endpoint to fetch all orders and logs its hash code to verify its singleton nature:</p> <pre><code>@RestController\n@RequestMapping(\"/api/orders\")\n@RequiredArgsConstructor\n@Slf4j\npublic class OrderController {\n\n    private final OrderService orderService;\n\n    @GetMapping\n    public ResponseEntity&lt;List&lt;OrderDTO&gt;&gt; findAll() {\n        log.info(\"OrderController HashCode: {}\", System.identityHashCode(this));\n\n        var response = orderService.findAll()\n                .stream()\n                .map(order -&gt; new OrderDTO(order.getName(), order.getDescription()))\n                .toList();\n        return ResponseEntity.status(HttpStatus.OK).body(response);\n    }\n}\n</code></pre>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#3-order-service","title":"3. Order Service","text":"<p>The service layer handles business logic and also logs its hash code, along with the repository's:</p> <pre><code>@Service\n@RequiredArgsConstructor\n@Slf4j\npublic class OrderService {\n\n    private final OrderRepository orderRepository;\n\n    public List&lt;Order&gt; findAll() {\n        log.info(\"OrderService HashCode: {}\", System.identityHashCode(this));\n        log.info(\"OrderRepository HashCode: {}\", System.identityHashCode(orderRepository));\n\n        return orderRepository.findAll();\n    }\n}\n</code></pre>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#observing-singleton-behavior-in-logs","title":"Observing Singleton Behavior in Logs","text":"<p>When you run the application and make multiple requests to <code>/api/orders</code>, the logs will show the same hash code for each instance. In my case, the hash codes were:</p> <pre><code>OrderController HashCode: 12345678\nOrderService HashCode: 87654321\nOrderRepository HashCode: 23456789\n</code></pre> <p>These consistent hash codes confirm that Spring is using the same instance of each bean across all requests.</p>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#how-spring-handles-concurrent-requests-with-thread-pools","title":"How Spring Handles Concurrent Requests with Thread Pools","text":"<p>You might wonder: if these components are singletons, how does Spring handle multiple requests concurrently?</p> <p>The answer lies in thread pools. Spring\u2019s default thread pool (backed by the servlet container, such as Tomcat) assigns each incoming HTTP request to a separate thread. Each thread executes the same singleton instance of your controller, service, and repository, ensuring that multiple requests can be processed concurrently.</p>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#key-points","title":"Key Points:","text":"<ul> <li>The singleton components themselves are not thread-safe by design, but the stateless nature of most services and repositories makes them safe for multi-threaded access.</li> <li>If your service or controller maintains state (e.g., using class-level variables), you must ensure thread safety manually, as multiple threads can access the same singleton instance simultaneously.</li> </ul>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#why-use-singletons","title":"Why Use Singletons?","text":"<ol> <li>Efficiency: Singletons reduce memory usage and initialization overhead since only one instance is created.</li> <li>Consistency: Using a single instance ensures that the state and configuration are consistent throughout the application.</li> </ol>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#wrap-up","title":"Wrap Up","text":"<p>Singletons, when combined with thread pools, allow Spring applications to scale efficiently without creating multiple instances of components. By logging <code>System.identityHashCode</code>, we verified that Spring uses the same instance of our beans across all requests. However, always remember to keep your singleton components stateless to avoid threading issues in multi-threaded environments.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"spring/How%20to%20Scale%20Spring%20Boot%20for%20High%20Concurrency/","title":"How to Scale Spring Boot for High Concurrency","text":"<p>In my previous post, we explored how Spring Boot uses singleton-scoped components (like controllers, services, and repositories) and how multiple threads can safely share these instances thanks to stateless design. We verified singleton behavior using <code>System.identityHashCode</code> and explained how Spring delegates concurrent request processing to the servlet container\u2019s thread pool (e.g., Tomcat).</p> <p>In this follow-up post, we go one level deeper \u2014 tackling questions like:</p> <ul> <li>What happens when concurrent user traffic increases?</li> <li>Should you increase the Tomcat thread pool size?</li> <li>How do you determine the right number of threads?</li> <li>How do you monitor and tune your Spring Boot app for concurrency?</li> </ul>"},{"location":"spring/How%20to%20Scale%20Spring%20Boot%20for%20High%20Concurrency/#spring-boot-uses-thread-pools-for-concurrency","title":"Spring Boot Uses Thread Pools for Concurrency","text":"<p>Every incoming HTTP request is assigned to a thread from a shared thread pool maintained by the embedded servlet container (e.g., Tomcat, Jetty, or Undertow).  This makes your app capable of handling multiple users simultaneously, even though your beans are singleton-scoped.</p> <p>But here\u2019s the catch: the thread pool has limits.</p> <p>If all threads are busy:</p> <ul> <li>Incoming requests are queued</li> <li>If the queue is full, then requests are rejected or delayed</li> </ul>"},{"location":"spring/How%20to%20Scale%20Spring%20Boot%20for%20High%20Concurrency/#when-should-you-increase-the-thread-pool-size","title":"When Should You Increase the Thread Pool Size?","text":"<p>If your application starts experiencing, slow response times, request timeouts, or 5xx errors under load it might be time to look at  your Tomcat thread pool settings.</p> <p>You can configure them in <code>application.yml</code>:</p> <pre><code>server:\n  tomcat:\n    threads:\n      max: 200     # default is 200\n      min-spare: 10\n</code></pre> <p>But how do you know what number is right?</p>"},{"location":"spring/How%20to%20Scale%20Spring%20Boot%20for%20High%20Concurrency/#rule-of-thumb-io-bound-vs-cpu-bound","title":"Rule of Thumb: I/O-Bound vs. CPU-Bound","text":"<p>Your thread pool sizing depends on the nature of your workload:</p>"},{"location":"spring/How%20to%20Scale%20Spring%20Boot%20for%20High%20Concurrency/#for-io-bound-applications","title":"For I/O-Bound Applications","text":"<p>(e.g., database queries, external HTTP calls)</p> <ul> <li>Threads often sit idle waiting for I/O</li> <li>You can afford to have more threads than CPU cores</li> <li>Start with: 2x to 4x the number of cores</li> </ul>"},{"location":"spring/How%20to%20Scale%20Spring%20Boot%20for%20High%20Concurrency/#for-cpu-bound-applications","title":"For CPU-Bound Applications","text":"<p>(e.g., heavy computation, encoding)</p> <ul> <li>Threads are CPU-hungry</li> <li>More threads \u2192 more context switching \u2192 slower performance</li> <li>Match threads to number of CPU cores: maxThreads \u2248 CPU cores</li> </ul>"},{"location":"spring/How%20to%20Scale%20Spring%20Boot%20for%20High%20Concurrency/#example","title":"Example","text":"<p>If your server has 8 cores:</p> <ul> <li>I/O-heavy service: try <code>maxThreads = 32\u201364</code></li> <li>CPU-heavy service: try <code>maxThreads = 8</code></li> </ul> <p>Always monitor and adjust.</p>"},{"location":"spring/How%20to%20Scale%20Spring%20Boot%20for%20High%20Concurrency/#monitoring-thread-pool-usage","title":"Monitoring Thread Pool Usage","text":"<p>To make informed decisions, observe the actual load on your thread pool. You can do this using:</p>"},{"location":"spring/How%20to%20Scale%20Spring%20Boot%20for%20High%20Concurrency/#spring-boot-actuator-micrometer","title":"Spring Boot Actuator + Micrometer","text":"<p>Enable actuator endpoints and integrate with:</p> <ul> <li>Prometheus</li> <li>Grafana</li> <li>CloudWatch, New Relic, etc.</li> </ul> <p>Look for:</p> <ul> <li><code>tomcat.threads.active</code></li> <li><code>tomcat.threads.max</code></li> <li><code>tomcat.threads.busy</code></li> </ul>"},{"location":"spring/How%20to%20Scale%20Spring%20Boot%20for%20High%20Concurrency/#jvisualvm-or-jfr","title":"JVisualVM or JFR","text":"<p>For local testing, tools like VisualVM or Java Flight Recorder help track:</p> <ul> <li>Thread activity</li> <li>Garbage collection</li> <li>Stack traces and bottlenecks</li> </ul> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/","title":"Method-Level Authorization in Spring Security","text":"<p>In this post, we'll explore how to use Spring Security to control access both at  the endpoint and method level using a sample project.  We'll cover role-based and authority-based security, showing how both can be configured  and used to enhance your application's overall security posture.</p> <ul> <li>Source code : Spring Security Method-Level Authorization Demo</li> </ul>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/#spring-security-configuration","title":"Spring Security Configuration","text":"<p>To get started, we need to configure Spring Security. Below is the <code>SecurityConfig</code> class, which is responsible for setting up the security rules and ensuring proper authentication and authorization for our application. With Spring Security, you can create custom security policies that help protect your application from unauthorized access.</p> <pre><code>@Bean\npublic SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n    http\n            .csrf(AbstractHttpConfigurer::disable)\n            .authorizeHttpRequests(auth -&gt; auth\n                    .requestMatchers(\"/public/**\").permitAll() // Allow access to public endpoints\n                    .requestMatchers(\"/admin/api/**\").hasRole(\"ADMIN\") // Require ADMIN role for admin endpoints\n                    .requestMatchers(\"/api/**\").hasRole(\"USER\") // Require USER role for general endpoints\n                    .anyRequest().authenticated()\n            )\n            .httpBasic(Customizer.withDefaults());\n\n    return http.build();\n}\n</code></pre> <p>The <code>SecurityFilterChain</code> bean is responsible for defining how requests are secured. We start by disabling CSRF protection for simplicity (note that in production, you should consider enabling it for non-API requests). Spring evaluates the matchers in the order they are defined in the authorizeHttpRequests block, stopping at the first match. This means that if multiple matchers overlap or are too generic, the earlier ones will take precedence, potentially overriding more restrictive rules.</p> <p>This layered approach to authorization allows us to provide clear boundaries for different types of users within our application, ensuring that each user only has access to the features they need.</p> <pre><code>@Bean\npublic UserDetailsService userDetailsService() {\n    var user1 = User.withUsername(\"user1\")\n            .password(\"{noop}user1\")\n            .roles(\"USER\")\n            .build();\n\n    var admin1 = User.withUsername(\"admin1\")\n            .password(\"{noop}admin1\")\n            .roles(\"ADMIN\")\n            .build();\n\n    var admin2 = User.withUsername(\"admin2\")\n            .password(\"{noop}admin2\")\n            .authorities(\"ROLE_ADMIN\", \"CREATE_ORDER\")\n            .build();\n\n    return new InMemoryUserDetailsManager(user1, admin1, admin2);\n}\n</code></pre> <p>In this configuration, we set up an <code>InMemoryUserDetailsManager</code> with three users: <code>user1</code>, <code>admin1</code>, and <code>admin2</code>. The user <code>user1</code> has the role <code>USER</code>, while <code>admin1</code> has the role <code>ADMIN</code>. Additionally, <code>admin2</code> has both the <code>ADMIN</code> role and an extra authority called <code>CREATE_ORDER</code>, which allows them to perform more specific actions, such as creating orders.</p> <p>In addition to HTTP Basic authentication, this configuration can easily be extended to include OAuth2 or JWT-based authentication to provide more sophisticated security mechanisms. </p>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/#applying-method-level-authorization","title":"Applying Method-Level Authorization","text":"<p>To illustrate how to implement method-level authorization, we have two controllers in our project: </p> <ul> <li>The <code>AdminController</code> handles administrative operations related to orders, while </li> <li>the general <code>Controller</code> manages regular user orders. </li> </ul> <p>By having separate controllers for different roles, we ensure that the application follows the principle of least privilege, where users only access the data they need.</p> <pre><code>@RestController\n@RequestMapping(\"/admin/api/orders\")\npublic class AdminController {\n\n    @GetMapping\n    public String getOrders() {\n        return \"Admin orders returned\";\n    }\n\n    @PostMapping\n    @PreAuthorize(\"hasAuthority('CREATE_ORDER')\")\n    public String createOrder() {\n        return \"Order created\";\n    }\n}\n</code></pre> <p>In the <code>AdminController</code>, there are two endpoints. The <code>GET</code> endpoint returns a list of orders, while the <code>POST</code> endpoint is used to create a new order. The <code>POST</code> endpoint is protected using the <code>@PreAuthorize</code> annotation to ensure that only users with the <code>CREATE_ORDER</code> authority can access it.</p> <p>The <code>@PreAuthorize</code> annotation is a powerful feature provided by Spring Security that allows you to specify authorization requirements at the method level. In this case, only users with the <code>CREATE_ORDER</code> authority are allowed to create a new order. This allows us to provide more granular control over access, ensuring that sensitive actions are restricted to users with the appropriate permissions.</p> <pre><code>@RestController\n@RequestMapping(\"/api/orders\")\npublic class Controller {\n\n    @GetMapping\n    public String getOrders() {\n        return \"Orders returned\";\n    }\n}\n</code></pre> <p>The general <code>Controller</code> is used for managing orders accessible to regular users. This controller does not have any special method-level security annotations, as it is intended for users with the <code>USER</code> role. </p>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/#response-examples-for-endpoint-requests","title":"Response Examples for Endpoint Requests","text":"<p>Here are some examples of the responses for different requests made to the API endpoints:</p> <pre><code>GET localhost:8080/api/orders\n\nHTTP 401 Unauthorized\n{\n  \"error\": \"Unauthorized\",\n  \"message\": \"Full authentication is required to access this resource\"\n}\n</code></pre> <pre><code>GET localhost:8080/api/orders\nAuthorization: Basic user1 user1\n\nHTTP 200 OK\nOrders returned\n</code></pre> <pre><code>GET localhost:8080/admin/api/orders\nAuthorization: Basic admin1 admin1\n\nHTTP 200 OK\nAdmin orders returned\n</code></pre> <pre><code>POST localhost:8080/admin/api/orders\nAuthorization: Basic admin1 admin1\n\nHTTP 403 Forbidden\n{\n  \"error\": \"Forbidden\",\n  \"message\": \"Access is denied\"\n}\n</code></pre> <pre><code>POST localhost:8080/admin/api/orders\nAuthorization: Basic admin2 admin2\n\nHTTP 200 OK\nOrder created\n</code></pre>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/#roles-vs-authorities","title":"Roles vs Authorities","text":"<p>Roles are a specific type of authority in Spring Security, distinguished by the <code>\"ROLE_\"</code> prefix in their names. For example, <code>.roles(\"ADMIN\")</code> is equivalent to <code>.authorities(\"ROLE_ADMIN\")</code>.</p> <p>However, caution is needed when mixing <code>roles</code> and <code>authorities</code> while configuring user permissions. In the example below, the user will have only the <code>CREATE_ORDER</code> authority because <code>.authorities(\"CREATE_ORDER\")</code> overrides <code>.roles(\"ADMIN\")</code>.</p> <pre><code>var admin = User.withUsername(\"admin\")\n    .password(\"{noop}admin\")\n    .roles(\"ADMIN\") // This is translated to \"ROLE_ADMIN\"\n    .authorities(\"CREATE_ORDER\") // This overrides the role\n    .build();\n</code></pre> <p>In such cases, explicitly specify all desired authorities in <code>.authorities()</code> to avoid unintentional overrides.</p>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/#additional-considerations-for-method-level-security","title":"Additional Considerations for Method-Level Security","text":"<p>Additionally, method-level security annotations like <code>@PreAuthorize</code> can be combined with other annotations such as <code>@PostAuthorize</code>, <code>@Secured</code>, and <code>@RolesAllowed</code> to provide even more flexibility. For instance, <code>@PostAuthorize</code> can be used to validate the response after the method has executed, which can be helpful in certain scenarios, such as ensuring that a user only sees data they are allowed to access.</p> <p>Happy coding! \ud83d\udcbb</p>"}]}
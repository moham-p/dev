{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Hi</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/","title":"PostgreSQL Transactions - Part 1","text":"<p>Understanding transactions is a foundational skill in database systems. Transactions are critical for ensuring database reliability and consistency. By exploring transactions, you can:</p> <ul> <li>Build robust, error-resilient applications.</li> <li>Debug database behaviors with confidence.</li> <li>Design systems that handle concurrency and consistency gracefully.</li> </ul> <p>Curiosity about transactions is a gateway to mastering how databases work behind the scenes. PostgreSQL\u2019s handling of transactions, even for simple queries, offers insights into how databases maintain ACID properties (Atomicity, Consistency, Isolation, Durability).</p> <ul> <li>Source code : Spring boot / JPA / PostgreSQL</li> </ul>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#exploring-postgresql-transactions-with-a-simple-select-query-in-spring-boot","title":"Exploring PostgreSQL Transactions with a Simple SELECT Query in Spring Boot","text":"<p>When we think about database transactions, the focus is often on <code>INSERT</code>, <code>UPDATE</code>, or <code>DELETE</code> queries. But did you know that even a simple <code>SELECT</code> query in PostgreSQL is part of a transaction? Let's build a simple demo project to verify this behavior.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#code-setup-a-minimal-spring-boot-example","title":"Code Setup: A Minimal Spring Boot Example","text":"<p>Here\u2019s a simple setup to illustrate the concept:</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#entity","title":"Entity","text":"<pre><code>@Entity\n@Data\npublic class AccountEntity {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    private String name;\n    private int balance;\n}\n</code></pre>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#repository","title":"Repository","text":"<pre><code>public interface AccountRepository extends JpaRepository&lt;AccountEntity, Long&gt; {\n}\n</code></pre>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#service","title":"Service","text":"<pre><code>@Service\n@AllArgsConstructor\npublic class AccountService {\n\n    private final AccountRepository accountRepository;\n\n    public List&lt;AccountEntity&gt; getAllAccounts() {\n        return accountRepository.findAll();\n    }\n}\n</code></pre>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#controller","title":"Controller","text":"<pre><code>@RestController\n@AllArgsConstructor\npublic class AccountController {\n\n    private final AccountService accountService;\n\n    @GetMapping(\"/accounts\")\n    public List&lt;AccountEntity&gt; getAllAccounts() {\n        return accountService.getAllAccounts();\n    }\n}\n</code></pre> <p>To observe transactions in action, enable logging in <code>postgresql.conf</code>:</p> <pre><code>log_statement = 'all'\n</code></pre> <p>Now, make a request to: <pre><code>GET localhost:8080/accounts\n</code></pre></p> <p>Here\u2019s what you\u2019ll see in the PostgreSQL logs:</p> <p><pre><code>execute &lt;unnamed&gt;: BEGIN READ ONLY\nexecute &lt;unnamed&gt;: select ae1_0.id,ae1_0.balance,ae1_0.name from account_entity ae1_0\nexecute &lt;unnamed&gt;: COMMIT\n</code></pre> Notice that the query is executed between BEGIN READ ONLY and COMMIT, which marks the boundaries of the transaction.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#postgresql-transactional-nature","title":"PostgreSQL Transactional Nature","text":"<p>In PostgreSQL, every query is executed in a transaction, whether explicitly declared or not. We didn\u2019t explicitly define <code>@Transactional</code> in our service method <code>getAllAccounts</code>. However, PostgreSQL\u2019s default autocommit mode implicitly wraps the query in its own transaction and commits it immediately after the query finishes.</p> <p>If you want to explicitly define transactions in your service methods that deal with reading data, you can do so by using the annotation <code>@Transactional(readOnly = true)</code>.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#why-autocommit-exists","title":"Why Autocommit Exists","text":"<ul> <li>PostgreSQL ensures that all queries are atomic, consistent, isolated, and durable (ACID properties).</li> <li>Even a <code>SELECT</code> benefits from this, as it guarantees the query operates on a consistent snapshot of the database.</li> </ul>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%201/#why-consistency-matters-for-select-queries","title":"Why Consistency Matters for SELECT Queries","text":"<p>A snapshot in a transaction refers to the consistent view of the database that a query or set of queries operates on. Don\u2019t forget that <code>SELECT</code> operations can include complex joins across many tables.  These operations are executed as a single <code>SELECT</code> query (PostgreSQL does not split a complex join into subqueries).</p> <p>A complex join involves multiple tables and potentially millions of rows. Without a consistent snapshot, intermediate states (caused by concurrent updates, inserts, or deletes) could lead to:</p> <ul> <li>Inconsistent Results: The query might see partial updates from other transactions.</li> <li>Phantom Reads: Rows that didn\u2019t exist at the start of the query might suddenly appear due to concurrent inserts.</li> </ul> <p>Therefore, Having a consistent snapshot of the database during execution is critical for maintaining data accuracy and consistency, especially in environments with concurrent transactions.</p> <p>In the next part, we continue our curiosity-driven journey by exploring the behavior of update queries.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/","title":"PostgreSQL Transactions - Part 2","text":"<p>In part one, we explained how SELECT queries benefit from running as a transaction. In this part, let\u2019s explore why transactions are essential for UPDATE statements.</p> <p>We mentioned earlier that autocommit mode is the default in PostgreSQL. This means that if you do not explicitly use BEGIN to start a transaction, each individual SQL statement (SELECT, INSERT, UPDATE, DELETE, etc.) is treated as a separate transaction. PostgreSQL will automatically commit the statement immediately after its execution.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#importance-of-transactions-for-update-statements","title":"Importance of Transactions for UPDATE Statements","text":"<p>Running UPDATE statements as transactions is essential because modifications to a database require ACID compliance to ensure reliability and data integrity.</p> <p>When using UPDATE statements, we need to apply changes as a set of units in an all-or-nothing fashion. This is achieved through the Atomicity property of transactions. Additionally, if something goes wrong during the update, it is critical to restore the database to a valid state, ensuring data integrity. This is made possible by the Consistency property of transactions. The rollback mechanism in transactions prevents the database from being left in an invalid state due to partially completed operations.</p> <p>Moreover, we rely on the Isolation property provided by transactions. Isolation ensures that SELECT statements (and other queries) operate on a consistent view of the database, often referred to as a \"snapshot.\"</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#postgresql-isolation-levels","title":"PostgreSQL Isolation Levels","text":"<p>The default isolation level in PostgreSQL is Read Committed, which ensures that queries only see data that has been committed. However, changes made within a transaction are not visible to other transactions until the transaction is committed. This isolation level is sufficient for most applications.</p> <p>For use cases that require stricter isolation, PostgreSQL offers two higher levels:</p> <ol> <li>Repeatable Read: Provides a consistent snapshot of data for the entire duration of a transaction, preventing non-repeatable reads (when the same query returns different results due to concurrent updates).</li> <li>Serializable: The strictest isolation level, simulating sequential transaction execution. It prevents all concurrency anomalies, including phantom reads.</li> </ol>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#phantom-reads-and-isolation-challenges","title":"Phantom Reads and Isolation Challenges","text":"<p>Phantom Reads exemplify isolation challenges: - A transaction retrieves rows with <code>SELECT * FROM person WHERE age &gt; 30;</code>. - If another transaction inserts a row with <code>age = 35</code> and commits, rerunning the query would include the new row, creating a \"phantom\" effect.</p> <p>While Repeatable Read prevents some anomalies, it does not eliminate phantoms. Serializable isolation, however, ensures that even these are addressed by effectively serializing transaction execution.</p> <p>Isolation is particularly important in multi-user environments, where multiple transactions interact and can lead to complex concurrency issues.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#locking-mechanisms-outside-of-transactions","title":"Locking Mechanisms Outside of Transactions","text":"<p>Locks can also be used outside of transactions, providing manual control over database resources. For example, the LOCK TABLE statement allows users to explicitly lock a table or specific rows to manage custom workflows, independent of transactional logic.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#examples-of-row-level-locks","title":"Examples of Row-Level Locks:","text":"<ol> <li> <p><code>SELECT FOR UPDATE</code>    Locks selected rows to prevent concurrent modifications. Other transactions are blocked from updating or deleting these rows until the lock is released.</p> </li> <li> <p><code>SELECT FOR SHARE</code>    Acquires a less restrictive lock on rows, allowing other transactions to read the rows but preventing modifications. This is useful when you need to ensure rows are not updated or deleted while being processed, but without blocking other readers.</p> </li> </ol> <p>These locking mechanisms are particularly valuable for fine-tuned control over database operations in complex workflows.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#select-for-update-vs-optimistic-locking","title":"<code>SELECT FOR UPDATE</code> vs. Optimistic Locking","text":""},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#select-for-update-pessimistic-locking","title":"<code>SELECT FOR UPDATE</code> (Pessimistic Locking)","text":"<p>This approach is ideal for high-conflict scenarios, such as avoiding double-booking issues. However, it can degrade performance due to contention, as rows are locked and other transactions are blocked from modifying them until the lock is released.</p> <p>To address these limitations, optimistic locking is an alternative strategy that assumes conflicts are rare.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#optimistic-locking","title":"Optimistic Locking","text":"<p>Optimistic locking avoids locking rows during read operations, allowing other transactions to read or write to the same rows concurrently. It relies on versioning to detect conflicts at the time of committing changes.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#how-it-works","title":"How It Works:","text":"<ol> <li>A version column (or timestamp) is added to the table to track changes to rows.</li> <li>During an UPDATE, the query checks if the version column matches the expected value:<ul> <li>If the version matches, the update proceeds, and the version column is incremented.</li> <li>If the version does not match, the update fails, signaling that another transaction has modified the row, resulting in a concurrency exception.</li> </ul> </li> </ol>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#example","title":"Example:","text":"<p>Table Setup with a Version Column <pre><code>CREATE TABLE account (\n    id SERIAL PRIMARY KEY,\n    balance INT NOT NULL,\n    version INT NOT NULL\n);\n</code></pre></p> <p>Optimistic Update Query <pre><code>UPDATE account\nSET balance = 500, version = version + 1\nWHERE id = 1 AND version = 58;\n</code></pre></p> <p>If the condition <code>version = 58</code> fails (e.g., another transaction has already updated the row and incremented the version), the update will not proceed. This approach is lightweight and works best in scenarios where conflicts are infrequent, as it avoids the overhead of maintaining locks.</p>"},{"location":"data/PostgreSQL%20Transactions%20-%20Part%202/#practical-tips-for-transaction-management","title":"Practical Tips for Transaction Management","text":"<ol> <li> <p>Choose the Right Isolation Level</p> <ul> <li>Use Read Committed for general-purpose applications, as it balances performance and consistency.</li> <li>Opt for Repeatable Read when consistent snapshots are needed, particularly in read-heavy operations.</li> <li>Choose Serializable for scenarios requiring the highest level of data integrity, such as financial transactions, where avoiding anomalies is critical.</li> </ul> </li> <li> <p>Leverage Locking Strategically</p> <ul> <li>Use locks judiciously to maintain a balance between performance and consistency.</li> <li>For example, prefer <code>SELECT FOR UPDATE</code> in high-conflict situations to prevent double-booking or simultaneous modifications.</li> </ul> </li> <li> <p>Optimize for Concurrency</p> <ul> <li>In high-concurrency environments, favor optimistic locking to reduce contention and improve performance.</li> <li>This approach minimizes the overhead of holding locks while still ensuring consistency by checking for conflicts at commit time.</li> </ul> </li> </ol> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/","title":"Correlating Bamboo Concepts with AWS ECS","text":"<p>When managing CI/CD pipelines with Atlassian Bamboo and deploying containerized workloads using AWS Elastic Container Service (ECS), understanding how their concepts align can help streamline workflows. This post explores how Bamboo and ECS can complement each other, enabling parallel usage for seamless integration of CI/CD and container orchestration.</p>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#atlassian-bamboo-concepts","title":"Atlassian Bamboo Concepts","text":"<ol> <li> <p>Project    A project in Bamboo is a logical grouping of plans, representing a high-level entity such as an application, service, or product.    Example: For a \"Payment System,\" the project might include multiple plans for backend, frontend, and database components.</p> </li> <li> <p>Plan    A plan is a sequence of jobs that define how your code is built, tested, and packaged. This forms the foundation of Bamboo\u2019s CI pipeline.    Example: A backend plan could involve steps to compile Java code, run unit tests, and package it into a JAR file.</p> </li> <li> <p>Deployment    Deployment in Bamboo refers to delivering an application or artifact (produced by a plan) to a specific environment, such as development, staging, or production.    Example: A deployment plan outlines the steps for deploying the application to a staging environment, including configuration changes.</p> </li> <li> <p>Release    A release is a versioned snapshot of your software, ready for deployment. It represents a stable build after passing tests.    Example: Version <code>1.0.0</code> of your application is tagged as a release and marked as ready for production.</p> </li> </ol>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#mapping-bamboo-concepts-to-aws-ecs-for-parallel-usage","title":"Mapping Bamboo Concepts to AWS ECS for Parallel Usage","text":"<p>While Bamboo manages CI/CD workflows, AWS ECS focuses on container orchestration. These tools can work together, with Bamboo feeding ECS through seamless CI/CD pipelines. Here's how their concepts align:</p> <ol> <li> <p>Project \u2192 ECS Cluster or Application Group    A Bamboo project can correspond to an ECS cluster or a grouping of services within your infrastructure.    Example: The \"Payment System\" project in Bamboo maps to an ECS cluster hosting multiple services.</p> </li> <li> <p>Plan \u2192 ECS Task Definition    Bamboo plans can handle the CI pipeline for building and packaging Docker containers, which are then referenced in ECS task definitions.    Example: A Bamboo plan builds a Docker container and pushes it to Amazon ECR, ready for deployment in ECS.</p> </li> <li> <p>Deployment \u2192 ECS Service Update    Bamboo deployments can trigger ECS service updates, rolling out new versions of containers to specific environments like staging or production.    Example: A Bamboo deployment task updates the ECS service with a new task definition.</p> </li> <li> <p>Release \u2192 Docker Image Version or Task Definition Revision    Bamboo releases can represent versioned Docker images or ECS task definition revisions, providing stability and consistency.    Example: A release like <code>payment-backend:1.0.0</code> is tagged in Bamboo and used as a task definition in ECS.</p> </li> </ol>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#configuring-bamboo-plans-using-iac-with-java","title":"Configuring Bamboo Plans Using IaC with Java","text":"<p>Bamboo allows plans to be defined and managed programmatically using Infrastructure as Code (IaC). This approach ensures consistency, repeatability, and easier integration with version control systems. As of now, Atlassian Bamboo supports Java (via the Bamboo Specs API) and YAML (for declarative configurations).</p>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#example-defining-a-bamboo-plan-with-java","title":"Example: Defining a Bamboo Plan with Java","text":"<pre><code>// Initialize Bamboo Server\nBambooServer bambooServer = new BambooServer(\"https://your-bamboo-server.com\");\n\n// Create the Bamboo Plan\nPlan plan = new Plan(\n    new Project().key(\"DOCKER\").name(\"Docker Project\"),\n    \"Docker Image Build Plan\",\n    \"DIB\")\n    .description(\"Plan to build Docker images for ECS deployment\")\n    .stages(\n        new Stage(\"Build Stage\")\n            .jobs(new Job(\"Build and Dockerize Job\", \"BUILD\")\n                .tasks(\n                    // Step 1: Checkout the source code\n                    new VcsCheckoutTask()\n                        .description(\"Checkout Code\")\n                        .checkoutItems(new CheckoutItem().repository(\"MyRepo\")),\n\n                    // Step 2: Build the application (e.g., Maven build)\n                    new ScriptTask()\n                        .description(\"Build Application\")\n                        .inlineBody(\"mvn clean install\"),\n\n                    // Step 3: Build the Docker image\n                    new DockerBuildImageTask()\n                        .description(\"Build Docker Image\")\n                        .imageName(\"my-ecr-repo/my-app:latest\")\n                        .dockerfileInWorkingDir()\n                )\n            )\n    );\n\n// Publish the plan to Bamboo\nbambooServer.publish(plan);\n\nSystem.out.println(\"Plan published successfully!\");\n</code></pre>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#choosing-between-java-and-yaml","title":"Choosing Between Java and YAML","text":"Feature Java YAML Complexity Suitable for complex configurations Ideal for simple and straightforward setups Flexibility Highly flexible, supports logic and dynamic plans Limited to static declarative configurations Ease of Use Requires Java knowledge and tools Easy for non-developers to use Tooling IDE support, type checking Plain text editor is sufficient <p>For most teams, YAML is easier for basic use cases, while Java offers the power and flexibility needed for advanced configurations. This approach complements AWS ECS, where you can similarly define infrastructure using tools like AWS CloudFormation or Terraform, enabling end-to-end IaC workflows.</p>"},{"location":"devops/Correlating%20Bamboo%20Concepts%20with%20AWS%20ECS/#conclusion","title":"Conclusion","text":"<p>Using Bamboo and AWS ECS in parallel leverages the strengths of both platforms: Bamboo\u2019s robust CI/CD pipelines and ECS\u2019s efficient container orchestration. Adding IaC capabilities to Bamboo plans using Java enhances automation, consistency, and collaboration. Together, these tools empower teams to streamline workflows, scale workloads, and maintain reliable deployments across diverse environments.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/","title":"Using Nginx to Front Both Backend and Frontend","text":"<p>When setting up a web application with a Spring Boot backend and a React frontend, you can choose to deploy them directly or use Nginx as a reverse proxy. Both options are viable, but using Nginx offers several advantages, especially for production environments.</p>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#1-without-nginx-direct-setup","title":"1. Without Nginx: Direct Setup","text":"<p>In this scenario, the backend and frontend are served directly to clients on their respective ports:</p> <ul> <li>Frontend URL: <code>http://localhost:4200</code> (React)</li> <li>Backend URL: <code>http://localhost:8085</code> (Spring Boot)</li> </ul>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#pros","title":"Pros:","text":"<ul> <li>Simplicity: No need for additional tools or configuration.</li> <li>Direct Access: Requests go straight to the backend or frontend, minimizing latency.</li> </ul>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#cons","title":"Cons:","text":"<ul> <li>CORS Issues: Since frontend (React) and backend (Spring Boot) are hosted on different origins, you'll need to configure CORS in Spring Boot. This adds complexity and potential security risks. </li> </ul> <p>Note: An origin is defined by the combination of the protocol, host, and port. Therefore, the URLs above are considered different origins because the ports (4200 vs. 8085) differ, even though the protocol and host are the same.</p>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#handling-cors-in-spring-boot","title":"Handling CORS in Spring Boot","text":"<p>Spring Boot provides the <code>@CrossOrigin</code> annotation, which allows fine-grained control over cross-origin resource sharing. Here\u2019s an example of how to configure a specific controller to handle CORS requests:</p> <pre><code>@CrossOrigin\n@RestController\n@RequestMapping(\"/account\")\npublic class AccountController {\n\n    @GetMapping(\"/{id}\")\n    public Account retrieve(@PathVariable Long id) {\n        // Fetch account details\n        return new Account(); // Example logic\n    }\n}\n</code></pre>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#explanation","title":"Explanation:","text":"<ol> <li><code>@CrossOrigin</code>: This annotation, when used with its default configuration, enables cross-origin requests for all origins.</li> <li>Controller-level CORS Configuration: You can apply this annotation to individual methods or at the class level for all endpoints within the controller.</li> <li>Methods Supported: In the example, both <code>GET</code> and <code>DELETE</code> requests are exposed for CORS handling.</li> </ol> <p>While this approach is effective, it requires specifying the allowed origins manually and might not scale well for dynamic environments.</p>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#2-with-nginx-reverse-proxy-setup","title":"2. With Nginx: Reverse Proxy Setup","text":"<p>Using Nginx as a reverse proxy creates a unified entry point for both services. Nginx routes requests based on their paths:</p> <ul> <li>Frontend URL: <code>http://localhost:9002</code> (Served through Nginx)</li> <li>Backend API: <code>http://localhost:9002/api</code></li> </ul>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#pros_1","title":"Pros:","text":"<ul> <li>Unified Access Point: Both services are accessible on the same port. For example:<ul> <li><code>/</code> serves the React app.</li> <li><code>/api/*</code> routes to the Spring Boot backend.</li> </ul> </li> <li>Avoid CORS Issues: Since Nginx proxies requests internally, the frontend and backend appear as a single origin.</li> <li>SSL Termination: Nginx can handle HTTPS traffic, enhancing security in production.</li> <li>Load Balancing: Distributes traffic among multiple instances of your backend or frontend.</li> <li>Static Content Caching: Speeds up static file delivery and reduces backend load.</li> <li>Enhanced Security: Supports rate limiting, IP filtering, and other protective measures.</li> </ul>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#example-nginx-configuration","title":"Example Nginx Configuration","text":"<p>Here\u2019s a sample <code>Nginx.conf</code> for routing requests to the frontend and backend:</p> <pre><code>server {\n    listen 80;\n\n    # Route requests for the React frontend\n    location / {\n        proxy_pass http://localhost:4200;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n\n    # Route API requests to the Spring Boot backend\n    location /api/ {\n        proxy_pass http://localhost:8085;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n}\n</code></pre>"},{"location":"devops/Using%20Nginx%20to%20Front%20Both%20Backend%20and%20Frontend/#conclusion","title":"Conclusion","text":"<ul> <li>Without Nginx: Best for local development or simple setups where CORS issues can be managed, and scalability isn\u2019t a concern.</li> <li>With Nginx: Ideal for production environments requiring unified access, better security, and scalability.</li> </ul> <p>Whether you choose to go with or without Nginx depends on your specific use case, but understanding how to handle CORS is essential for smooth backend and frontend communication. Let me know if you\u2019d like to dive deeper into any aspect of this configuration!</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/How%20HashMap%20Handles%20Collisions/","title":"How HashMap Handles Collisions","text":"<p>Collisions in a <code>HashMap</code> occur when multiple keys hash to the same bucket index. This situation arises because different keys can produce the same hash value. To handle such cases, <code>HashMap</code> employs separate chaining, where it stores multiple key-value pairs in a bucket using a linked list (or a balanced tree for performance optimization, starting from Java 8).</p> <p>Let\u2019s dive into an example to understand how this works.</p>"},{"location":"java/How%20HashMap%20Handles%20Collisions/#the-code-simulating-collisions","title":"The Code: Simulating Collisions","text":"<p>The following example demonstrates what happens when multiple keys in a <code>HashMap</code> collide due to having the same hash code:</p> <pre><code>import java.util.HashMap;\n\npublic class HashMapCollisionExample {\n    public static void main(String[] args) {\n\n       var map = new HashMap&lt;KeyWithSameHash, String&gt;();\n       map.put(new KeyWithSameHash(\"Key1\"), \"Value1\");\n       map.put(new KeyWithSameHash(\"Key2\"), \"Value2\");\n       map.put(new KeyWithSameHash(\"Key3\"), \"Value3\");\n\n       // prints Value3\n       System.out.println(map.get(new KeyWithSameHash(\"Key3\")));\n    }\n}\n\nclass KeyWithSameHash {\n    private String key;\n\n    public KeyWithSameHash(String key) {\n        this.key = key;\n    }\n\n    @Override\n    public int hashCode() {\n        return 1001; // Causes all keys to hash to the same bucket\n    }\n\n    @Override\n    public boolean equals(Object obj) {\n        if (this == obj) return true;\n        if (obj == null || getClass() != obj.getClass()) return false;\n        KeyWithSameHash other = (KeyWithSameHash) obj;\n        return key.equals(other.key);\n    }\n\n    @Override\n    public String toString() {\n        return key;\n    }\n}\n</code></pre>"},{"location":"java/How%20HashMap%20Handles%20Collisions/#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":"<ol> <li> <p>Hash Code Calculation    When you call <code>map.put(new KeyWithSameHash(\"Key3\"), \"Value3\")</code>, the <code>hashCode()</code> method of the key returns <code>1001</code> for all instances, forcing all keys to map to the same bucket.</p> </li> <li> <p>Bucket Index Determination    Although the hash code is <code>1001</code>, the bucket index is calculated using a bitwise operation (<code>hashCode % bucketArrayLength</code>), ensuring entries are distributed across available buckets. However, in this case, all keys land in the same bucket because their hash codes are identical.</p> </li> <li> <p>Collision Handling    Since multiple keys are mapped to the same bucket, <code>HashMap</code> handles the collision using a linked list (or balanced tree). Each entry in the bucket is stored as a node in the list.</p> </li> <li> <p>Key Lookup    When you retrieve a value using a key (e.g., <code>new KeyWithSameHash(\"Key3\")</code>), the <code>HashMap</code>:</p> <ul> <li>Finds the bucket for the key.</li> <li>Traverses the linked list in that bucket.</li> <li>Compares each key in the list using the <code>equals()</code> method until it finds a match.</li> </ul> </li> <li> <p>Value Retrieval    Once the key is located (where <code>equals()</code> returns <code>true</code>), the corresponding value is returned.</p> </li> </ol>"},{"location":"java/How%20HashMap%20Handles%20Collisions/#retrieval-complexity","title":"Retrieval Complexity","text":"<p>Despite all keys having the same hash code, the <code>HashMap</code> successfully retrieves the correct value due to its <code>equals()</code> comparison mechanism. However, retrieval complexity can degrade to (O(n)) if all keys hash to the same bucket and the bucket uses a linked list, or to (O(log n)) if the bucket uses a balanced tree (introduced in Java 8).</p>"},{"location":"java/How%20HashMap%20Handles%20Collisions/#wrap-up","title":"Wrap Up","text":"<ol> <li>Efficient Collision Handling: <code>HashMap</code> can handle collisions gracefully using separate chaining, ensuring reliable behavior even when hash codes collide.</li> <li>Importance of Proper <code>hashCode</code> Implementation: A poor hash code implementation, as shown in this example, can lead to performance degradation since all keys fall into the same bucket.</li> <li>Balanced Trees for Performance: Starting with Java 8, <code>HashMap</code> replaces the linked list with a balanced tree when collisions exceed a threshold, improving lookup times in heavily collided buckets.</li> </ol> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/","title":"Stay Friends with the Console","text":"<p>As developers, we often choose tools that enhance productivity and streamline our workflows. For Java developers, IntelliJ IDEA and Visual Studio Code (VS Code) are two popular choices. Each brings unique strengths to the table\u2014IntelliJ's rich UI simplifies complex setups, while VS Code's explicit configurations encourage familiarity with command-line operations.</p> <p>But here's a critical observation: developers using IntelliJ often become less familiar with the actual commands their tools execute behind the scenes. This post argues why staying \"friends with the console\" is vital, even if you rely on an IDE with advanced features.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#the-abstraction-gap","title":"The Abstraction Gap","text":"<p>When you run a project in IntelliJ IDEA, the process feels seamless: - Select a run configuration. - Click the green play button. - Watch your application start.</p> <p>Behind the scenes, IntelliJ generates a command to launch your application, passing JVM arguments, system properties, and classpath settings. However, many developers don\u2019t inspect this command, creating a knowledge gap. Over time, this reliance on the UI can lead to an aversion to using the console.</p> <p>In contrast, VS Code's <code>launch.json</code> file makes you explicitly define every aspect of your run configuration: - The main class to launch. - The JVM arguments to include. - Environment variables and debugging options.</p> <p>This approach forces you to understand the command being executed, fostering a deeper awareness of what\u2019s happening under the hood.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#why-it-matters","title":"Why It Matters","text":""},{"location":"java/Stay%20Friends%20with%20the%20Console/#1-portability","title":"1. Portability","text":"<p>Knowing the command being executed allows you to replicate the same setup outside your IDE. This is especially critical in environments like CI/CD pipelines, where everything runs on the command line.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#2-debugging-skills","title":"2. Debugging Skills","text":"<p>When something breaks in production, you won\u2019t have IntelliJ\u2019s UI to save you. Understanding how to craft and troubleshoot the equivalent command-line invocation ensures you're better equipped to diagnose and resolve issues.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#3-tool-independence","title":"3. Tool Independence","text":"<p>Becoming overly reliant on an IDE can tie your productivity to that tool. By understanding the underlying commands, you\u2019re not just an IntelliJ user; you\u2019re a developer who can adapt to any environment.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#bridging-the-gap","title":"Bridging the Gap","text":""},{"location":"java/Stay%20Friends%20with%20the%20Console/#1-inspect-run-configurations","title":"1. Inspect Run Configurations:","text":"<p>Every time you run your application, IntelliJ logs the generated command in the Run or Debug console. Take a moment to review it. Understand the JVM arguments, the classpath, and any system properties being passed.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#2-experiment-with-the-command-line","title":"2. Experiment with the Command Line:","text":"<p>Copy the command from IntelliJ\u2019s logs and execute it directly in your terminal. Modify parameters, try different options, and see how your application behaves.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#3-translate-ui-to-commands","title":"3. Translate UI to Commands:","text":"<p>When setting up run configurations in IntelliJ, think about how you\u2019d define the same setup in a tool like VS Code or Maven. This mental exercise helps solidify your understanding.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#4-leverage-tools-like-maven-and-gradle","title":"4. Leverage Tools Like Maven and Gradle:","text":"<p>These tools are designed for command-line execution and often integrate seamlessly with IDEs. Practice running your application with commands like the following:</p> <p>Command Generated by IntelliJ:    <pre><code>/Users/youruser/.sdkman/candidates/java/21.0.1-amzn/bin/java \\\n-Dspring.output.ansi.enabled=always \\\n-Dfile.encoding=UTF-8 \\\n-classpath /Users/youruser/project/target/classes:/Users/youruser/.m2/repository/org/springframework/... \\\ncom.example.Application\n</code></pre></p> <p>Equivalent Maven Command:    <pre><code>mvn spring-boot:run \\\n-Dspring-boot.run.jvmArguments=\"-Dspring.output.ansi.enabled=always -Dfile.encoding=UTF-8\"\n</code></pre></p> <ul> <li>IntelliJ: Handles the classpath and configuration automatically but abstracts the process.</li> <li>Maven: Provides a clear and portable way to replicate the same execution, ensuring you stay familiar with the underlying mechanics.</li> </ul>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#embrace-the-best-of-both-worlds","title":"Embrace the Best of Both Worlds","text":"<p>Using IntelliJ IDEA doesn\u2019t mean abandoning the console. Instead, think of the IDE as a tool that enhances your productivity without replacing foundational knowledge. When you understand the commands your IDE generates, you unlock a new level of control over your development process.</p> <p>Whether you\u2019re configuring a debugging session, tweaking JVM options, or deploying your application to production, staying friends with the console ensures you remain on top of your craft.</p>"},{"location":"java/Stay%20Friends%20with%20the%20Console/#final-thought","title":"Final Thought","text":"<p>An IDE should simplify your workflow, not shield you from understanding it. So, the next time you click \"Run\" in IntelliJ, take a moment to explore the command it generates. It\u2019s not just a helpful exercise\u2014it\u2019s a step toward becoming a more confident and capable developer.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/","title":"Seamless AWS Access - Setting Up Azure AD as a Federated Identity Provider","text":"<p>Imagine you run a growing organization where employees need access to AWS services. Managing individual IAM users for each employee would be complex and inefficient. This is where identity federation becomes a game-changer. Instead of creating separate IAM users, you can configure Azure AD as an identity provider, allowing employees to log into AWS using their existing Azure AD credentials. This setup leverages SAML federation, ensuring seamless and secure access management without the overhead of IAM user administration.</p> <p>In this blog post, we'll explore identity federation, its key concepts, and how to set up Azure AD as an identity provider for AWS.</p>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#what-is-federation","title":"What is Federation?","text":"<p>Federation enables users to authenticate using their existing credentials from a trusted identity provider (IdP) rather than creating separate accounts for different applications. This allows multiple systems or organizations to establish trust, enabling Single Sign-On (SSO) and seamless access to resources across different platforms.</p>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#key-concepts-in-federation","title":"Key Concepts in Federation","text":""},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#federated-identity-saml-federation","title":"Federated Identity (SAML Federation)","text":"<ul> <li>Users authenticate via an external identity provider (IdP) instead of managing credentials separately for each application.</li> <li>For example, logging into a website using Google or Facebook credentials means the identity is federated.</li> <li>The identity provider verifies the user's credentials and shares user attributes (such as email and user ID) with the relying application.</li> </ul>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#delegated-authentication","title":"Delegated Authentication","text":"<ul> <li>Instead of handling authentication directly, an application (OAuth2 client) delegates the process to an external provider.</li> <li>Protocols like SAML and OpenID Connect (OIDC) are commonly used for this, depending on the use case.</li> <li>The OAuth2 authorization server trusts the identity provider to authenticate the user securely.</li> </ul>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#single-sign-on-sso","title":"Single Sign-On (SSO)","text":"<ul> <li>Federation allows SSO, meaning users authenticate once and can access multiple applications without needing to log in again.</li> <li>Example: Employees signing into corporate applications via Azure AD gain access to various services without repeated logins.</li> </ul>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#identity-providers-idps","title":"Identity Providers (IdPs)","text":"<ul> <li>Common identity providers used in a federated OAuth2 setup include:</li> <li>Google</li> <li>Facebook</li> <li>Azure AD</li> <li>Okta</li> <li>Any SAML or OpenID Connect compliant provider</li> <li>The SAML or OpenID Connect provider establishes a federation relationship with these IdPs, allowing authentication via external credentials.</li> </ul>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#configuring-azure-ad-as-an-identity-provider-for-aws","title":"Configuring Azure AD as an Identity Provider for AWS","text":"<p>Organizations often use Azure AD for authentication while running workloads on AWS. By integrating AWS IAM Identity Center (formerly AWS SSO) with Azure AD, users can log in to AWS resources using their Azure credentials.</p>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#steps-to-set-up-azure-ad-for-aws-access","title":"Steps to Set Up Azure AD for AWS Access","text":"<ol> <li>Configure IAM Roles for SAML Users</li> <li>In AWS IAM, create roles with permissions needed for users.</li> <li>Link the role with the identity provider by configuring the SAML trust relationship.</li> <li>Define role mappings in AWS IAM Identity Center, so users receive appropriate permissions upon logging in.</li> <li>AWS STS will issue temporary credentials for users based on their assigned role.</li> <li>Enable IAM Identity Center in AWS: Navigate to IAM Identity Center in the AWS console and select External Identity Provider.</li> <li>Register AWS in Azure AD: In the Azure Portal, add AWS as an enterprise application under Azure Active Directory.</li> <li>Configure SAML in Azure AD: Enable Single Sign-On (SSO) and set up SAML attributes.</li> <li>Integrate with AWS IAM Identity Center: Upload the Azure AD Metadata XML in AWS and configure user mappings.</li> <li>Assign Users and Groups: Ensure assigned users/groups match in both Azure AD and AWS IAM Identity Center.</li> <li>Test the Integration: Verify login via Azure AD and check role-based access.</li> </ol>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#saml-federation-flow","title":"SAML Federation Flow","text":"<ol> <li>User attempts to log in to an application.</li> <li>The application redirects the user to a SAML identity provider (e.g., Azure AD).</li> <li>The user authenticates with the identity provider.</li> <li>The identity provider returns a SAML assertion to AWS IAM Identity Center.</li> <li>AWS Security Token Service (STS) issues temporary security credentials based on the SAML assertion.</li> <li>The user assumes an IAM role in AWS, granting them appropriate permissions.</li> <li>The application uses these temporary credentials to grant access to AWS resources.</li> </ol>"},{"location":"security/Seamless%20AWS%20Access%20-%20Setting%20Up%20Azure%20AD%20as%20a%20Federated%20Identity%20Provider/#key-benefits","title":"Key Benefits","text":"<ul> <li>Centralized Access Management: Manage AWS permissions via Azure AD.</li> <li>Single Sign-On: Users authenticate once to access AWS services.</li> <li>Enhanced Security: Enforce Conditional Access Policies and MFA.</li> </ul> <p>With this setup, organizations can leverage Azure AD\u2019s security while ensuring streamlined access control in AWS.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"soft-skills/Invisible%20Ownership%20Subtasks/","title":"Invisible Ownership Subtasks","text":"<p>When software developers pick up a new ticket, they often see a list of clearly defined subtasks\u2014requirements documented in tools like Jira that need to be completed to move the ticket forward. However, the best developers recognize that visible subtasks are only part of the picture. There's another category, the \"invisible ownership subtasks,\" that distinguishes those who truly take ownership from those who just check the boxes.</p> <p>Invisible ownership subtasks are those that never make it into a ticket management system. They require thinking about the wider impact of the change\u2014how it affects other modules, edge cases, and dependencies. Developers with this mindset have a deeper sense of responsibility and seek to understand the consequences of their work.</p> <p>A developer with low ownership might complete all visible subtasks, mark the ticket as \"done,\" and move on. In contrast, developers with high ownership see each ticket as part of a larger system they are responsible for. They ask questions like:</p> <ul> <li>How does this change impact related modules?</li> <li>Are there any integration concerns?</li> <li>If this change is introducing a new dependency to some libraries, how will it get built in CI/CD?</li> <li>If this is a backend change, how is it going to affect database migrations and downstream reports?</li> <li>Are there any security implications related to this change?</li> <li>How will this impact performance under load?</li> <li>What are the testing requirements for these changes to ensure robustness?\"</li> </ul> <p>Basically, every ticket has the potential to give you deeper knowledge of how different subsystems and teams in your company work, if you keep your curiosity alive and thriving.</p> <p>These invisible subtasks reveal the depth of a developer's engagement and often make the difference between a patchy implementation and a robust solution. Managers can use this concept to assess their team's level of ownership. Developers who ask about broader implications and take proactive steps demonstrate greater ownership. They don't just close a ticket\u2014they ensure the change is successful in every dimension.</p> <p>Cultivating this kind of ownership requires a supportive environment. Managers need to create a culture where curiosity is encouraged, and developers feel empowered to take extra time to address invisible subtasks. Encouraging invisible ownership shifts teams from a culture of ticket-closing to one of high-quality, impactful development.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/","title":"How Singleton Components Work with Thread Pools","text":"<p>Spring\u2019s component model is built on the principle of singletons for many of its core beans, ensuring efficiency and consistency across your application. If you\u2019ve ever wondered how Spring handles multiple requests while maintaining a single instance for components like controllers, services, and repositories, this article will walk you through it with practical examples and insights.</p> <ul> <li>Source code : Singleton Components Demo</li> </ul>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#what-are-singletons-in-spring","title":"What are Singletons in Spring?","text":"<p>In Spring, the default scope of beans is <code>singleton</code>, which means Spring creates exactly one instance of a bean per application context. This single instance is shared across all requests, ensuring consistency and reducing overhead.</p> <p>To verify that components like controllers, services, and repositories are singletons, you can use <code>System.identityHashCode</code> to print the unique memory reference hash for each bean instance.</p>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#verifying-singleton-behavior-with-code","title":"Verifying Singleton Behavior with Code","text":"<p>Let\u2019s take a look at a simple Spring Boot application to demonstrate this.</p>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#1-order-entity","title":"1. Order Entity","text":"<p>This entity represents a basic <code>Order</code> object stored in a database:</p> <pre><code>@Entity\n@Table(name = \"orders\")\n@Data\n@Builder\n@NoArgsConstructor\n@AllArgsConstructor\npublic class Order {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    private String name;\n    private String description;\n}\n</code></pre>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#2-order-controller","title":"2. Order Controller","text":"<p>The controller exposes an endpoint to fetch all orders and logs its hash code to verify its singleton nature:</p> <pre><code>@RestController\n@RequestMapping(\"/api/orders\")\n@RequiredArgsConstructor\n@Slf4j\npublic class OrderController {\n\n    private final OrderService orderService;\n\n    @GetMapping\n    public ResponseEntity&lt;List&lt;OrderDTO&gt;&gt; findAll() {\n        log.info(\"OrderController HashCode: {}\", System.identityHashCode(this));\n\n        var response = orderService.findAll()\n                .stream()\n                .map(order -&gt; new OrderDTO(order.getName(), order.getDescription()))\n                .toList();\n        return ResponseEntity.status(HttpStatus.OK).body(response);\n    }\n}\n</code></pre>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#3-order-service","title":"3. Order Service","text":"<p>The service layer handles business logic and also logs its hash code, along with the repository's:</p> <pre><code>@Service\n@RequiredArgsConstructor\n@Slf4j\npublic class OrderService {\n\n    private final OrderRepository orderRepository;\n\n    public List&lt;Order&gt; findAll() {\n        log.info(\"OrderService HashCode: {}\", System.identityHashCode(this));\n        log.info(\"OrderRepository HashCode: {}\", System.identityHashCode(orderRepository));\n\n        return orderRepository.findAll();\n    }\n}\n</code></pre>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#observing-singleton-behavior-in-logs","title":"Observing Singleton Behavior in Logs","text":"<p>When you run the application and make multiple requests to <code>/api/orders</code>, the logs will show the same hash code for each instance. In my case, the hash codes were:</p> <pre><code>OrderController HashCode: 12345678\nOrderService HashCode: 87654321\nOrderRepository HashCode: 23456789\n</code></pre> <p>These consistent hash codes confirm that Spring is using the same instance of each bean across all requests.</p>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#how-spring-handles-concurrent-requests-with-thread-pools","title":"How Spring Handles Concurrent Requests with Thread Pools","text":"<p>You might wonder: if these components are singletons, how does Spring handle multiple requests concurrently?</p> <p>The answer lies in thread pools. Spring\u2019s default thread pool (backed by the servlet container, such as Tomcat) assigns each incoming HTTP request to a separate thread. Each thread executes the same singleton instance of your controller, service, and repository, ensuring that multiple requests can be processed concurrently.</p>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#key-points","title":"Key Points:","text":"<ul> <li>The singleton components themselves are not thread-safe by design, but the stateless nature of most services and repositories makes them safe for multi-threaded access.</li> <li>If your service or controller maintains state (e.g., using class-level variables), you must ensure thread safety manually, as multiple threads can access the same singleton instance simultaneously.</li> </ul>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#why-use-singletons","title":"Why Use Singletons?","text":"<ol> <li>Efficiency: Singletons reduce memory usage and initialization overhead since only one instance is created.</li> <li>Consistency: Using a single instance ensures that the state and configuration are consistent throughout the application.</li> </ol>"},{"location":"spring/How%20Singleton%20Components%20Work%20with%20Thread%20Pools/#wrap-up","title":"Wrap Up","text":"<p>Singletons, when combined with thread pools, allow Spring applications to scale efficiently without creating multiple instances of components. By logging <code>System.identityHashCode</code>, we verified that Spring uses the same instance of our beans across all requests. However, always remember to keep your singleton components stateless to avoid threading issues in multi-threaded environments.</p> <p>Happy coding! \ud83d\udcbb</p>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/","title":"Method-Level Authorization in Spring Security","text":"<p>In this post, we'll explore how to use Spring Security to control access both at  the endpoint and method level using a sample project.  We'll cover role-based and authority-based security, showing how both can be configured  and used to enhance your application's overall security posture.</p> <ul> <li>Source code : Spring Security Method-Level Authorization Demo</li> </ul>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/#spring-security-configuration","title":"Spring Security Configuration","text":"<p>To get started, we need to configure Spring Security. Below is the <code>SecurityConfig</code> class, which is responsible for setting up the security rules and ensuring proper authentication and authorization for our application. With Spring Security, you can create custom security policies that help protect your application from unauthorized access.</p> <pre><code>@Bean\npublic SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n    http\n            .csrf(AbstractHttpConfigurer::disable)\n            .authorizeHttpRequests(auth -&gt; auth\n                    .requestMatchers(\"/public/**\").permitAll() // Allow access to public endpoints\n                    .requestMatchers(\"/admin/api/**\").hasRole(\"ADMIN\") // Require ADMIN role for admin endpoints\n                    .requestMatchers(\"/api/**\").hasRole(\"USER\") // Require USER role for general endpoints\n                    .anyRequest().authenticated()\n            )\n            .httpBasic(Customizer.withDefaults());\n\n    return http.build();\n}\n</code></pre> <p>The <code>SecurityFilterChain</code> bean is responsible for defining how requests are secured. We start by disabling CSRF protection for simplicity (note that in production, you should consider enabling it for non-API requests). Spring evaluates the matchers in the order they are defined in the authorizeHttpRequests block, stopping at the first match. This means that if multiple matchers overlap or are too generic, the earlier ones will take precedence, potentially overriding more restrictive rules.</p> <p>This layered approach to authorization allows us to provide clear boundaries for different types of users within our application, ensuring that each user only has access to the features they need.</p> <pre><code>@Bean\npublic UserDetailsService userDetailsService() {\n    var user1 = User.withUsername(\"user1\")\n            .password(\"{noop}user1\")\n            .roles(\"USER\")\n            .build();\n\n    var admin1 = User.withUsername(\"admin1\")\n            .password(\"{noop}admin1\")\n            .roles(\"ADMIN\")\n            .build();\n\n    var admin2 = User.withUsername(\"admin2\")\n            .password(\"{noop}admin2\")\n            .authorities(\"ROLE_ADMIN\", \"CREATE_ORDER\")\n            .build();\n\n    return new InMemoryUserDetailsManager(user1, admin1, admin2);\n}\n</code></pre> <p>In this configuration, we set up an <code>InMemoryUserDetailsManager</code> with three users: <code>user1</code>, <code>admin1</code>, and <code>admin2</code>. The user <code>user1</code> has the role <code>USER</code>, while <code>admin1</code> has the role <code>ADMIN</code>. Additionally, <code>admin2</code> has both the <code>ADMIN</code> role and an extra authority called <code>CREATE_ORDER</code>, which allows them to perform more specific actions, such as creating orders.</p> <p>In addition to HTTP Basic authentication, this configuration can easily be extended to include OAuth2 or JWT-based authentication to provide more sophisticated security mechanisms. </p>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/#applying-method-level-authorization","title":"Applying Method-Level Authorization","text":"<p>To illustrate how to implement method-level authorization, we have two controllers in our project: </p> <ul> <li>The <code>AdminController</code> handles administrative operations related to orders, while </li> <li>the general <code>Controller</code> manages regular user orders. </li> </ul> <p>By having separate controllers for different roles, we ensure that the application follows the principle of least privilege, where users only access the data they need.</p> <pre><code>@RestController\n@RequestMapping(\"/admin/api/orders\")\npublic class AdminController {\n\n    @GetMapping\n    public String getOrders() {\n        return \"Admin orders returned\";\n    }\n\n    @PostMapping\n    @PreAuthorize(\"hasAuthority('CREATE_ORDER')\")\n    public String createOrder() {\n        return \"Order created\";\n    }\n}\n</code></pre> <p>In the <code>AdminController</code>, there are two endpoints. The <code>GET</code> endpoint returns a list of orders, while the <code>POST</code> endpoint is used to create a new order. The <code>POST</code> endpoint is protected using the <code>@PreAuthorize</code> annotation to ensure that only users with the <code>CREATE_ORDER</code> authority can access it.</p> <p>The <code>@PreAuthorize</code> annotation is a powerful feature provided by Spring Security that allows you to specify authorization requirements at the method level. In this case, only users with the <code>CREATE_ORDER</code> authority are allowed to create a new order. This allows us to provide more granular control over access, ensuring that sensitive actions are restricted to users with the appropriate permissions.</p> <pre><code>@RestController\n@RequestMapping(\"/api/orders\")\npublic class Controller {\n\n    @GetMapping\n    public String getOrders() {\n        return \"Orders returned\";\n    }\n}\n</code></pre> <p>The general <code>Controller</code> is used for managing orders accessible to regular users. This controller does not have any special method-level security annotations, as it is intended for users with the <code>USER</code> role. </p>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/#response-examples-for-endpoint-requests","title":"Response Examples for Endpoint Requests","text":"<p>Here are some examples of the responses for different requests made to the API endpoints:</p> <pre><code>GET localhost:8080/api/orders\n\nHTTP 401 Unauthorized\n{\n  \"error\": \"Unauthorized\",\n  \"message\": \"Full authentication is required to access this resource\"\n}\n</code></pre> <pre><code>GET localhost:8080/api/orders\nAuthorization: Basic user1 user1\n\nHTTP 200 OK\nOrders returned\n</code></pre> <pre><code>GET localhost:8080/admin/api/orders\nAuthorization: Basic admin1 admin1\n\nHTTP 200 OK\nAdmin orders returned\n</code></pre> <pre><code>POST localhost:8080/admin/api/orders\nAuthorization: Basic admin1 admin1\n\nHTTP 403 Forbidden\n{\n  \"error\": \"Forbidden\",\n  \"message\": \"Access is denied\"\n}\n</code></pre> <pre><code>POST localhost:8080/admin/api/orders\nAuthorization: Basic admin2 admin2\n\nHTTP 200 OK\nOrder created\n</code></pre>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/#roles-vs-authorities","title":"Roles vs Authorities","text":"<p>Roles are a specific type of authority in Spring Security, distinguished by the <code>\"ROLE_\"</code> prefix in their names. For example, <code>.roles(\"ADMIN\")</code> is equivalent to <code>.authorities(\"ROLE_ADMIN\")</code>.</p> <p>However, caution is needed when mixing <code>roles</code> and <code>authorities</code> while configuring user permissions. In the example below, the user will have only the <code>CREATE_ORDER</code> authority because <code>.authorities(\"CREATE_ORDER\")</code> overrides <code>.roles(\"ADMIN\")</code>.</p> <pre><code>var admin = User.withUsername(\"admin\")\n    .password(\"{noop}admin\")\n    .roles(\"ADMIN\") // This is translated to \"ROLE_ADMIN\"\n    .authorities(\"CREATE_ORDER\") // This overrides the role\n    .build();\n</code></pre> <p>In such cases, explicitly specify all desired authorities in <code>.authorities()</code> to avoid unintentional overrides.</p>"},{"location":"spring/Method-Level%20Authorization%20in%20Spring%20Security/#additional-considerations-for-method-level-security","title":"Additional Considerations for Method-Level Security","text":"<p>Additionally, method-level security annotations like <code>@PreAuthorize</code> can be combined with other annotations such as <code>@PostAuthorize</code>, <code>@Secured</code>, and <code>@RolesAllowed</code> to provide even more flexibility. For instance, <code>@PostAuthorize</code> can be used to validate the response after the method has executed, which can be helpful in certain scenarios, such as ensuring that a user only sees data they are allowed to access.</p> <p>Happy coding! \ud83d\udcbb</p>"}]}